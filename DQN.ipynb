{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPyK5OLYS3Vse7ZrSLeBfVS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **REINFORCEMENT LEARNING PROJECT - DQN AGENT**"],"metadata":{"id":"CN4UEBcbD16d"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQTMJAYoxdpT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668118258449,"user_tz":-120,"elapsed":148061,"user":{"displayName":"Makoko Campbell Manape","userId":"01223048224952113583"}},"outputId":"5cffeacc-0e97-4394-bd51-718d056c9e8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:11 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,230 kB]\n","Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n","Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,472 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,040 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,554 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,271 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,332 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.9 kB]\n","Fetched 13.2 MB in 4s (3,056 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","5 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","build-essential is already the newest version (12.4ubuntu1).\n","pkg-config is already the newest version (0.29.1-0ubuntu2).\n","git is already the newest version (1:2.17.1-1ubuntu0.13).\n","libbz2-dev is already the newest version (1.0.6-8.1ubuntu0.2).\n","libbz2-dev set to manually installed.\n","python3-dev is already the newest version (3.6.7-1~18.04).\n","python3-dev set to manually installed.\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  automake autotools-dev file libbison-dev libfl-dev libfl2 libmagic-mgc\n","  libmagic1 libsigsegv2 m4 python-pip-whl python3-asn1crypto\n","  python3-cffi-backend python3-crypto python3-cryptography python3-idna\n","  python3-keyring python3-keyrings.alt python3-pkg-resources\n","  python3-secretstorage python3-setuptools python3-six python3-wheel\n","  python3-xdg\n","Suggested packages:\n","  autoconf-archive gnu-standards autoconf-doc gettext bison-doc flex-doc\n","  libtool-doc gcj-jdk m4-doc python-crypto-doc python-cryptography-doc\n","  python3-cryptography-vectors gnome-keyring libkf5wallet-bin\n","  gir1.2-gnomekeyring-1.0 python-numpy-doc python3-nose python3-numpy-dbg\n","  python-secretstorage-doc python-setuptools-doc\n","The following NEW packages will be installed:\n","  autoconf automake autotools-dev bison file flex libbison-dev libfl-dev\n","  libfl2 libmagic-mgc libmagic1 libsigsegv2 libtool m4 python-pip-whl\n","  python3-asn1crypto python3-cffi-backend python3-crypto python3-cryptography\n","  python3-idna python3-keyring python3-keyrings.alt python3-numpy python3-pip\n","  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n","  python3-wheel python3-xdg\n","0 upgraded, 30 newly installed, 0 to remove and 5 not upgraded.\n","Need to get 7,314 kB of archives.\n","After this operation, 33.3 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 flex amd64 2.6.4-6 [316 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libbison-dev amd64 2:3.0.4.dfsg-1build1 [339 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 bison amd64 2:3.0.4.dfsg-1build1 [266 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfl2 amd64 2.6.4-6 [11.4 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfl-dev amd64 2.6.4-6 [6,320 B]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtool all 2.4.6-2 [194 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n","Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-numpy amd64 1:1.13.3-2ubuntu1 [1,943 kB]\n","Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n","Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n","Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n","Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n","Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n","Fetched 7,314 kB in 4s (2,071 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 30.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libsigsegv2:amd64.\n","(Reading database ... 123942 files and directories currently installed.)\n","Preparing to unpack .../00-libsigsegv2_2.12-1_amd64.deb ...\n","Unpacking libsigsegv2:amd64 (2.12-1) ...\n","Selecting previously unselected package m4.\n","Preparing to unpack .../01-m4_1.4.18-1_amd64.deb ...\n","Unpacking m4 (1.4.18-1) ...\n","Selecting previously unselected package flex.\n","Preparing to unpack .../02-flex_2.6.4-6_amd64.deb ...\n","Unpacking flex (2.6.4-6) ...\n","Selecting previously unselected package libmagic-mgc.\n","Preparing to unpack .../03-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package libmagic1:amd64.\n","Preparing to unpack .../04-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package file.\n","Preparing to unpack .../05-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking file (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package autoconf.\n","Preparing to unpack .../06-autoconf_2.69-11_all.deb ...\n","Unpacking autoconf (2.69-11) ...\n","Selecting previously unselected package autotools-dev.\n","Preparing to unpack .../07-autotools-dev_20180224.1_all.deb ...\n","Unpacking autotools-dev (20180224.1) ...\n","Selecting previously unselected package automake.\n","Preparing to unpack .../08-automake_1%3a1.15.1-3ubuntu2_all.deb ...\n","Unpacking automake (1:1.15.1-3ubuntu2) ...\n","Selecting previously unselected package libbison-dev:amd64.\n","Preparing to unpack .../09-libbison-dev_2%3a3.0.4.dfsg-1build1_amd64.deb ...\n","Unpacking libbison-dev:amd64 (2:3.0.4.dfsg-1build1) ...\n","Selecting previously unselected package bison.\n","Preparing to unpack .../10-bison_2%3a3.0.4.dfsg-1build1_amd64.deb ...\n","Unpacking bison (2:3.0.4.dfsg-1build1) ...\n","Selecting previously unselected package libfl2:amd64.\n","Preparing to unpack .../11-libfl2_2.6.4-6_amd64.deb ...\n","Unpacking libfl2:amd64 (2.6.4-6) ...\n","Selecting previously unselected package libfl-dev:amd64.\n","Preparing to unpack .../12-libfl-dev_2.6.4-6_amd64.deb ...\n","Unpacking libfl-dev:amd64 (2.6.4-6) ...\n","Selecting previously unselected package libtool.\n","Preparing to unpack .../13-libtool_2.4.6-2_all.deb ...\n","Unpacking libtool (2.4.6-2) ...\n","Selecting previously unselected package python-pip-whl.\n","Preparing to unpack .../14-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n","Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Selecting previously unselected package python3-asn1crypto.\n","Preparing to unpack .../15-python3-asn1crypto_0.24.0-1_all.deb ...\n","Unpacking python3-asn1crypto (0.24.0-1) ...\n","Selecting previously unselected package python3-cffi-backend.\n","Preparing to unpack .../16-python3-cffi-backend_1.11.5-1_amd64.deb ...\n","Unpacking python3-cffi-backend (1.11.5-1) ...\n","Selecting previously unselected package python3-crypto.\n","Preparing to unpack .../17-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n","Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n","Selecting previously unselected package python3-idna.\n","Preparing to unpack .../18-python3-idna_2.6-1_all.deb ...\n","Unpacking python3-idna (2.6-1) ...\n","Selecting previously unselected package python3-six.\n","Preparing to unpack .../19-python3-six_1.11.0-2_all.deb ...\n","Unpacking python3-six (1.11.0-2) ...\n","Selecting previously unselected package python3-cryptography.\n","Preparing to unpack .../20-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n","Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n","Selecting previously unselected package python3-secretstorage.\n","Preparing to unpack .../21-python3-secretstorage_2.3.1-2_all.deb ...\n","Unpacking python3-secretstorage (2.3.1-2) ...\n","Selecting previously unselected package python3-keyring.\n","Preparing to unpack .../22-python3-keyring_10.6.0-1_all.deb ...\n","Unpacking python3-keyring (10.6.0-1) ...\n","Selecting previously unselected package python3-keyrings.alt.\n","Preparing to unpack .../23-python3-keyrings.alt_3.0-1_all.deb ...\n","Unpacking python3-keyrings.alt (3.0-1) ...\n","Selecting previously unselected package python3-numpy.\n","Preparing to unpack .../24-python3-numpy_1%3a1.13.3-2ubuntu1_amd64.deb ...\n","Unpacking python3-numpy (1:1.13.3-2ubuntu1) ...\n","Selecting previously unselected package python3-pip.\n","Preparing to unpack .../25-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n","Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Selecting previously unselected package python3-pkg-resources.\n","Preparing to unpack .../26-python3-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python3-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python3-setuptools.\n","Preparing to unpack .../27-python3-setuptools_39.0.1-2_all.deb ...\n","Unpacking python3-setuptools (39.0.1-2) ...\n","Selecting previously unselected package python3-wheel.\n","Preparing to unpack .../28-python3-wheel_0.30.0-0.2_all.deb ...\n","Unpacking python3-wheel (0.30.0-0.2) ...\n","Selecting previously unselected package python3-xdg.\n","Preparing to unpack .../29-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n","Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n","Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Setting up python3-cffi-backend (1.11.5-1) ...\n","Setting up libsigsegv2:amd64 (2.12-1) ...\n","Setting up python3-crypto (2.6.1-8ubuntu2) ...\n","Setting up python3-numpy (1:1.13.3-2ubuntu1) ...\n","Setting up python3-idna (2.6-1) ...\n","Setting up python3-xdg (0.25-4ubuntu1.1) ...\n","Setting up python3-six (1.11.0-2) ...\n","Setting up python3-wheel (0.30.0-0.2) ...\n","Setting up m4 (1.4.18-1) ...\n","Setting up python3-pkg-resources (39.0.1-2) ...\n","Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n","Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n","Setting up python3-asn1crypto (0.24.0-1) ...\n","Setting up autotools-dev (20180224.1) ...\n","Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Setting up libbison-dev:amd64 (2:3.0.4.dfsg-1build1) ...\n","Setting up libfl2:amd64 (2.6.4-6) ...\n","Setting up bison (2:3.0.4.dfsg-1build1) ...\n","update-alternatives: using /usr/bin/bison.yacc to provide /usr/bin/yacc (yacc) in auto mode\n","Setting up python3-setuptools (39.0.1-2) ...\n","Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n","Setting up flex (2.6.4-6) ...\n","Setting up python3-keyrings.alt (3.0-1) ...\n","Setting up autoconf (2.69-11) ...\n","Setting up file (1:5.32-2ubuntu0.4) ...\n","Setting up libfl-dev:amd64 (2.6.4-6) ...\n","Setting up automake (1:1.15.1-3ubuntu2) ...\n","update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n","Setting up python3-secretstorage (2.3.1-2) ...\n","Setting up libtool (2.4.6-2) ...\n","Setting up python3-keyring (10.6.0-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n","OK\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Get:10 https://apt.kitware.com/ubuntu bionic InRelease [11.0 kB]\n","Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Get:13 https://apt.kitware.com/ubuntu bionic/main amd64 Packages [67.8 kB]\n","Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Fetched 78.8 kB in 2s (37.0 kB/s)\n","Reading package lists... Done\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:11 https://apt.kitware.com/ubuntu bionic InRelease\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following packages were automatically installed and are no longer required:\n","  libarchive13 liblzo2-2 libnvidia-common-460 librhash0 libuv1\n","Use 'apt autoremove' to remove them.\n","The following additional packages will be installed:\n","  cmake-data\n","Suggested packages:\n","  cmake-doc ninja-build\n","The following NEW packages will be installed:\n","  kitware-archive-keyring\n","The following packages will be upgraded:\n","  cmake cmake-data\n","2 upgraded, 1 newly installed, 0 to remove and 5 not upgraded.\n","Need to get 13.6 MB of archives.\n","After this operation, 21.8 MB of additional disk space will be used.\n","Get:1 https://apt.kitware.com/ubuntu bionic/main amd64 cmake amd64 3.24.1-0kitware1ubuntu18.04.1 [11.6 MB]\n","Get:2 https://apt.kitware.com/ubuntu bionic/main amd64 cmake-data all 3.24.1-0kitware1ubuntu18.04.1 [1,986 kB]\n","Get:3 https://apt.kitware.com/ubuntu bionic/main amd64 kitware-archive-keyring all 2022.06.23 [20.1 kB]\n","Fetched 13.6 MB in 4s (3,620 kB/s)\n","Preconfiguring packages ...\n","(Reading database ... 125490 files and directories currently installed.)\n","Preparing to unpack .../cmake_3.24.1-0kitware1ubuntu18.04.1_amd64.deb ...\n","Unpacking cmake (3.24.1-0kitware1ubuntu18.04.1) over (3.10.2-1ubuntu2.18.04.2) ...\n","Preparing to unpack .../cmake-data_3.24.1-0kitware1ubuntu18.04.1_all.deb ...\n","Unpacking cmake-data (3.24.1-0kitware1ubuntu18.04.1) over (3.10.2-1ubuntu2.18.04.2) ...\n","Selecting previously unselected package kitware-archive-keyring.\n","Preparing to unpack .../kitware-archive-keyring_2022.06.23_all.deb ...\n","Unpacking kitware-archive-keyring (2022.06.23) ...\n","Setting up cmake-data (3.24.1-0kitware1ubuntu18.04.1) ...\n","Setting up kitware-archive-keyring (2022.06.23) ...\n","Setting up cmake (3.24.1-0kitware1ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","cmake version 3.24.1\n","\n","CMake suite maintained and supported by Kitware (kitware.com/cmake).\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nle\n","  Downloading nle-0.8.1.tar.gz (6.9 MB)\n","\u001b[K     |████████████████████████████████| 6.9 MB 14.7 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gym>=0.15 in /usr/local/lib/python3.7/dist-packages (from nle) (0.25.2)\n","Collecting pybind11>=2.2\n","  Using cached pybind11-2.10.1-py3-none-any.whl (216 kB)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from nle) (1.21.6)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.15->nle) (1.5.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.15->nle) (0.0.8)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.15->nle) (4.13.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.15->nle) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.15->nle) (3.10.0)\n","Building wheels for collected packages: nle\n","  Building wheel for nle (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nle: filename=nle-0.8.1-cp37-cp37m-linux_x86_64.whl size=2883125 sha256=2b80317a3de8f519ec0c1786b77e978bea3822ed7196e032851868a86295afa1\n","  Stored in directory: /root/.cache/pip/wheels/2f/43/b7/00eec64b2f64dc45883624bcb42a969645c86814ea751c6299\n","Successfully built nle\n","Installing collected packages: pybind11, nle\n","Successfully installed nle-0.8.1 pybind11-2.10.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting minihack\n","  Downloading minihack-0.1.3.tar.gz (223 kB)\n","\u001b[K     |████████████████████████████████| 223 kB 34.7 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nle>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from minihack) (0.8.1)\n","Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from minihack) (0.25.2)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from minihack) (1.21.6)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from nle>=0.8.0->minihack) (2.10.1)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym->minihack) (4.13.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->minihack) (1.5.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym->minihack) (0.0.8)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->minihack) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->minihack) (3.10.0)\n","Building wheels for collected packages: minihack\n","  Building wheel for minihack (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for minihack: filename=minihack-0.1.3-py3-none-any.whl size=261793 sha256=b29cf06107705143e30e4aef9c68565da56f1204a0f77b86a8b132acdec2263a\n","  Stored in directory: /root/.cache/pip/wheels/8c/b0/50/bb8c09fe5befa92b343025c26d614c5fa312f1edb432cc9580\n","Successfully built minihack\n","Installing collected packages: minihack\n","Successfully installed minihack-0.1.3\n"]}],"source":["## INSTALLATIONS.\n","!sudo apt update\n","!sudo apt install -y build-essential autoconf libtool pkg-config python3-dev \\\n","    python3-pip python3-numpy git flex bison libbz2-dev\n","\n","!wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | sudo apt-key add -\n","!sudo apt-add-repository 'deb https://apt.kitware.com/ubuntu/ bionic main'\n","!sudo apt-get update && apt-get --allow-unauthenticated install -y \\\n","    cmake \\\n","    kitware-archive-keyring\n","\n","# feel free to use a more elegant solution to make /usr/bin/cmake the default one\n","!sudo rm $(which cmake)\n","!$(which cmake) --version\n","\n","# install nle and minihack\n","!pip install nle\n","!pip install minihack"]},{"cell_type":"code","source":["## LIBRARIES\n","import os\n","import gym\n","import math\n","import torch\n","import random\n","import imageio\n","import minihack\n","import numpy as np\n","from model import DQN\n","from gym import spaces\n","from nle import nethack\n","from agent import DQNAgent\n","from google.colab import drive\n","import matplotlib.pyplot as plt\n","from IPython.display import Image\n","from minihack import RewardManager\n","from replay_buffer import ReplayBuffer"],"metadata":{"id":"uPDDmhrIzFPE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Code was adapted from [Here](https://github.com/raillab/dqn) and modified to fit our requirements."],"metadata":{"id":"xy6iyf4KU28o"}},{"cell_type":"code","source":["# 1. Mount google drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"id":"OftW_Ud3Pdwh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668118302547,"user_tz":-120,"elapsed":29699,"user":{"displayName":"Makoko Campbell Manape","userId":"01223048224952113583"}},"outputId":"59221d17-f7db-4398-e673-1645d186ba36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# 2. Set device to use GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"0KJmY_npEFKa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **1. HELPER FUNCTIONS**"],"metadata":{"id":"7W_eI2P7D8Hg"}},{"cell_type":"code","source":["def display_image(state):\n","  \"\"\"Displays the image of state['pixel'].\"\"\"\n","  img = np.uint8(state['pixel'])\n","  plt.figure(figsize=(15, 7))\n","  plt.imshow(img)\n","  plt.axis('off')\n","  plt.show()"],"metadata":{"id":"dZsm4M59KjJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def moving_average(arr, n):\n","  \"\"\"Calculates the moving average of an array arr, with a window size n\"\"\"\n","  cummulative_sum = np.cumsum(arr, dtype=float)\n","  cummulative_sum[n:] = cummulative_sum[n:] - cummulative_sum[:-n]\n","  return cummulative_sum / n"],"metadata":{"id":"yjANUqeMDuPx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_state(state):\n","  \"\"\"Formats the state into form that the CNN can accept\"\"\"\n","  glyphs = state[\"glyphs\"]\n","  glyphs = glyphs / glyphs.max() # Standardize the glyphs\n","  glyphs = glyphs.reshape((1, 1, 21, 79)) # reshape\n","  return torch.from_numpy(glyphs).squeeze(0)"],"metadata":{"id":"is6XWG2uDt1d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_results(scores):\n","  \"\"\"\n","  Plots the reward acquired by an agent at each step of training in \n","  an environment for each iteration and average over all iterations\n","  \"\"\"\n","  \n","  plt.figure(figsize=(8, 6))\n","  \n","  # Plot the scores \n","  for score in scores:\n","      plt.plot(score, color='blue', label='Learning curve')\n","  \n","  plt.title(\"DQN - Learning curve\")\n","  plt.xlabel(\"Episode Number\")\n","  plt.ylabel(\"Reward\")\n","  plt.legend()\n","  plt.savefig('DQN-learning curve')\n","  plt.show()"],"metadata":{"id":"8afME2jfDts_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2. TRAIN DQN AGENT**"],"metadata":{"id":"wHR-4AiPCq8C"}},{"cell_type":"code","source":["def train_dqn_agent(env, seed):\n","  \"\"\"\n","  Method to train DQN model.\n","  \n","  Input:\n","  env: The environment to be used during training\n","  seed: The random seed for any random operations performed\n","  \n","  Returns:\n","  scores: The cumulative reward achieved by the agent for each episode during traiing\n","  \"\"\"\n","\n","  hyper_params = {\n","      'replay-buffer-size': int(1e6),\n","      'learning-rate': 0.01,\n","      'gamma': 0.99,  # discount factor\n","      'num-steps': int(5e5),  # Steps to run for, max episodes should be hit before this\n","      'batch-size': 32,\n","      'learning-starts': 1000,  # set learning to start after 1000 steps of exploration\n","      'learning-freq': 1,  # Optimize after each step\n","      'use-double-dqn': True,\n","      'target-update-freq': 1000, # number of iterations between every target network update\n","      'eps-start': 1.0,  # e-greedy start threshold \n","      'eps-end': 0.1,  # e-greedy end threshold \n","      'eps-fraction': 0.4,  # Percentage of the time that epsilon is annealed\n","      'print-freq': 1,\n","  }\n","  \n","  np.random.seed(seed)\n","  env.seed(seed)\n","  \n","  # Create DQN agent\n","  replay_buffer = ReplayBuffer(hyper_params['replay-buffer-size'])\n","  agent = DQNAgent(\n","      env.observation_space, \n","      env.action_space,\n","      train=True,\n","      replay_buffer=replay_buffer,\n","      use_double_dqn=hyper_params['use-double-dqn'],\n","      lr=hyper_params['learning-rate'],\n","      batch_size=hyper_params['batch-size'],\n","      gamma=hyper_params['gamma'],\n","  )\n","  \n","  # define variables to track agent metrics\n","  total_reward = 0\n","  scores = []\n","  mean_rewards = []\n","\n","  # Reset gym env before training\n","  state = format_state(env.reset())\n","  eps_timesteps = hyper_params['eps-fraction'] * float(hyper_params['num-steps'])\n","\n","  # Train for set number of steps\n","  for t in range(hyper_params['num-steps']):\n","\n","    # determine exploration probability\n","    fract = min(1.0, float(t) / eps_timesteps)\n","    eps_threshold = hyper_params[\"eps-start\"] + fract * (hyper_params[\"eps-end\"] - hyper_params[\"eps-start\"])\n","    sample = random.random()\n","    \n","    # Decide to explore and choose random action or use model to act\n","    if sample < eps_threshold:\n","      action = np.random.choice(agent.action_space.n)\n","    else:\n","      action = agent.act(state)\n","    \n","    # Take step in environment\n","    (next_state, reward, done, _) = env.step(action)\n","    next_state = format_state(next_state)\n","    replay_buffer.add(state, action, reward, next_state, float(done))\n","    total_reward += reward\n","    state = next_state\n","\n","    if done:\n","      scores.append(total_reward)\n","      print(f\"episode reward: {total_reward}\")\n","      np.random.seed(seed)\n","      env.seed(seed)\n","      state = format_state(env.reset())\n","      total_reward = 0\n","\n","    if t > hyper_params['learning-starts'] and t % hyper_params['learning-freq'] == 0:\n","      ans = agent.optimise_td_loss()\n","\n","    if t > hyper_params['learning-starts'] and t % hyper_params['target-update-freq'] == 0:\n","      agent.update_target_network()\n","\n","    num_episodes = len(scores)\n","    if done and hyper_params['print-freq'] is not None and len(scores) % hyper_params['print-freq'] == 0:\n","      mean_100ep_reward = round(np.mean(scores[-101:-1]), 1)\n","      mean_rewards.append(mean_100ep_reward)\n","      print('********************************************************')\n","      print('steps: {}'.format(t))\n","      print('episodes: {}'.format(num_episodes))\n","      print('mean 100 episode reward: {}'.format(mean_100ep_reward))\n","      print('% time spent exploring: {}'.format(eps_threshold))\n","      print('********************************************************')\n","\n","      # save the model to google drive\n","      torch.save(agent.policy_network.state_dict(), f'/content/gdrive/MyDrive/RL PROJECT/dqn-checkpoint-{seed}.pth')\n","  return scores"],"metadata":{"id":"tvcTPw-2GnMG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reward for exploring more of the map\n","def maze_explore_reward_fn(env, prev_obs, action, next_obs):\n","  if (prev_obs[0] == 2359).sum() > (next_obs[0] == 2359).sum():\n","    return 0.1\n","  return 0"],"metadata":{"id":"AWrpQjp2oVLW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the environment with the observations keys required as input to the DQN\n","MOVE_ACTIONS = tuple(nethack.CompassDirection)\n","NAVIGATE_ACTIONS = MOVE_ACTIONS + (\n","    nethack.Command.PICKUP,\n","    nethack.Command.APPLY,\n","    nethack.Command.FIRE,\n","    nethack.Command.RUSH,\n","    nethack.Command.ZAP,\n","    nethack.Command.PUTON,\n","    nethack.Command.READ,\n","    nethack.Command.WEAR,\n","    nethack.Command.QUAFF,\n","    nethack.Command.PRAY\n","    )\n","\n","reward_manager = RewardManager()\n","\n","# 1. Reward killing monster\n","reward_manager.add_kill_event(\"minotaur\", reward=5, repeatable=False)\n","\n","# 2. Random reward included to prevent reward glitch \n","reward_manager.add_eat_event(\"apple\", reward=1)\n","\n","# 3. Custom rewards for long corridors at top and bottom \n","reward_manager.add_coordinate_event((3,27), reward = -10, terminal_required = False)\n","reward_manager.add_coordinate_event((3,28), reward = -10, terminal_required = False)\n","reward_manager.add_coordinate_event((3,29), reward = -10, terminal_required = False)\n","\n","reward_manager.add_coordinate_event((19,27), reward = -10, terminal_required = False)\n","reward_manager.add_coordinate_event((19,28), reward = -10, terminal_required = False)\n","reward_manager.add_coordinate_event((19,29), reward = -10, terminal_required = False)\n","\n","# 4. Reward for reaching the first door at end of maze\n","reward_manager.add_coordinate_event((11,27), reward = 10, terminal_required = False)\n","reward_manager.add_custom_reward_fn(maze_explore_reward_fn)"],"metadata":{"id":"1RDz5gyKDtbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. Make the environment.\n","env = gym.make(\"MiniHack-Quest-Hard-v0\", observation_keys=[\"glyphs\",\"pixel\",\"message\"],\n","               reward_win=100, reward_lose=-1, actions=NAVIGATE_ACTIONS, reward_manager=reward_manager)"],"metadata":{"id":"mByqWr5SorDc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668118327332,"user_tz":-120,"elapsed":2,"user":{"displayName":"Makoko Campbell Manape","userId":"01223048224952113583"}},"outputId":"8860e50b-473a-42da-8769-2e9bfb5e4e54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:32: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (21, 79)\u001b[0m\n","  \"A Box observation space has an unconventional shape (neither an image, nor a 1D vector). \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}]},{"cell_type":"code","source":["# 6. Reset the environment and display the screen of the starting state\n","display_image(env.reset())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"8QWrTthqCBkt","executionInfo":{"status":"ok","timestamp":1668118328439,"user_tz":-120,"elapsed":7,"user":{"displayName":"Makoko Campbell Manape","userId":"01223048224952113583"}},"outputId":"12a61d9e-9ed3-4e63-ea67-71b52a23be8c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x504 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# 7. Train the DQN Agent using diffrent seeds.\n","seeds = np.random.randint(100, size=1)\n","scores_array = []\n","\n","for seed in seeds:\n","  print('=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~')\n","  print('seed:', seed)\n","  print('=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~')\n","\n","  # Train the DQN Model\n","  scores = train_dqn_agent(env=env, seed=seed)\n","\n","  # Store rewards for this iteration\n","  scores_array.append(scores)\n","\n","  # Store rewards after each seed into binary file.\n","  np.save('/content/gdrive/MyDrive/RL PROJECT/dqn-quest_hard_scores', scores_array)"],"metadata":{"id":"2ZHJZTYUGnET","executionInfo":{"status":"ok","timestamp":1668128428301,"user_tz":-120,"elapsed":10090472,"user":{"displayName":"Makoko Campbell Manape","userId":"01223048224952113583"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"df1b0c5d-bb46-4ae2-ecc3-e79c9b4e2bfa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~\n","seed: 47\n","=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=~\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"output_type":"stream","name":"stdout","text":["episode reward: -0.7700000000000014\n","********************************************************\n","steps: 199\n","episodes: 1\n","mean 100 episode reward: nan\n","% time spent exploring: 0.9991045\n","********************************************************\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","% time spent exploring: 0.856\n","********************************************************\n","episode reward: -0.3400000000000005\n","********************************************************\n","steps: 32125\n","episodes: 139\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8554375000000001\n","********************************************************\n","episode reward: -0.9000000000000009\n","********************************************************\n","steps: 32340\n","episodes: 140\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.85447\n","********************************************************\n","episode reward: -1.1400000000000012\n","********************************************************\n","steps: 32550\n","episodes: 141\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.853525\n","********************************************************\n","episode reward: -1.0900000000000014\n","********************************************************\n","steps: 32765\n","episodes: 142\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8525575\n","********************************************************\n","episode reward: -0.49000000000000027\n","********************************************************\n","steps: 32903\n","episodes: 143\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8519365\n","********************************************************\n","episode reward: -0.030000000000000027\n","********************************************************\n","steps: 32954\n","episodes: 144\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.851707\n","********************************************************\n","episode reward: -1.8500000000000016\n","********************************************************\n","steps: 33216\n","episodes: 145\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.850528\n","********************************************************\n","episode reward: -1.220000000000001\n","********************************************************\n","steps: 33476\n","episodes: 146\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8493580000000001\n","********************************************************\n","episode reward: -0.8300000000000007\n","********************************************************\n","steps: 33637\n","episodes: 147\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8486335\n","********************************************************\n","episode reward: -1.390000000000001\n","********************************************************\n","steps: 33858\n","episodes: 148\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.847639\n","********************************************************\n","episode reward: -0.7900000000000008\n","********************************************************\n","steps: 34007\n","episodes: 149\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8469685\n","********************************************************\n","episode reward: -0.5300000000000005\n","********************************************************\n","steps: 34121\n","episodes: 150\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8464555\n","********************************************************\n","episode reward: -0.4500000000000003\n","********************************************************\n","steps: 34206\n","episodes: 151\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8460730000000001\n","********************************************************\n","episode reward: -3.3299999999999734\n","********************************************************\n","steps: 34667\n","episodes: 152\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8439985\n","********************************************************\n","episode reward: -0.42000000000000026\n","********************************************************\n","steps: 34750\n","episodes: 153\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8436250000000001\n","********************************************************\n","episode reward: -1.9000000000000024\n","********************************************************\n","steps: 35098\n","episodes: 154\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.842059\n","********************************************************\n","episode reward: -0.7600000000000007\n","********************************************************\n","steps: 35231\n","episodes: 155\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8414605\n","********************************************************\n","episode reward: -1.6900000000000015\n","********************************************************\n","steps: 35530\n","episodes: 156\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.840115\n","********************************************************\n","episode reward: -1.390000000000001\n","********************************************************\n","steps: 35756\n","episodes: 157\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.839098\n","********************************************************\n","episode reward: -1.430000000000001\n","********************************************************\n","steps: 35971\n","episodes: 158\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8381305\n","********************************************************\n","episode reward: -0.13000000000000014\n","********************************************************\n","steps: 36095\n","episodes: 159\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8375725\n","********************************************************\n","episode reward: -1.7600000000000018\n","********************************************************\n","steps: 36376\n","episodes: 160\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.836308\n","********************************************************\n","episode reward: -2.3399999999999945\n","********************************************************\n","steps: 36725\n","episodes: 161\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8347375\n","********************************************************\n","episode reward: -0.22000000000000014\n","********************************************************\n","steps: 36805\n","episodes: 162\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8343775\n","********************************************************\n","episode reward: -0.3500000000000004\n","********************************************************\n","steps: 36907\n","episodes: 163\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8339185\n","********************************************************\n","episode reward: -0.18000000000000022\n","********************************************************\n","steps: 36976\n","episodes: 164\n","mean 100 episode reward: -1.2\n","% time spent exploring: 0.833608\n","********************************************************\n","episode reward: -2.6199999999999886\n","********************************************************\n","steps: 37392\n","episodes: 165\n","mean 100 episode reward: -1.2\n","% time spent exploring: 0.831736\n","********************************************************\n","episode reward: -3.3399999999999728\n","********************************************************\n","steps: 37842\n","episodes: 166\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.829711\n","********************************************************\n","episode reward: -1.6500000000000015\n","********************************************************\n","steps: 38096\n","episodes: 167\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.828568\n","********************************************************\n","episode reward: -3.3699999999999655\n","********************************************************\n","steps: 38613\n","episodes: 168\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8262415000000001\n","********************************************************\n","episode reward: -1.5900000000000016\n","********************************************************\n","steps: 38888\n","episodes: 169\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.825004\n","********************************************************\n","episode reward: -1.0900000000000007\n","********************************************************\n","steps: 39076\n","episodes: 170\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.824158\n","********************************************************\n","episode reward: -2.949999999999981\n","********************************************************\n","steps: 39528\n","episodes: 171\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.822124\n","********************************************************\n","episode reward: -1.6500000000000017\n","********************************************************\n","steps: 39838\n","episodes: 172\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.820729\n","********************************************************\n","episode reward: -1.8300000000000014\n","********************************************************\n","steps: 40103\n","episodes: 173\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8195365\n","********************************************************\n","episode reward: -1.3700000000000012\n","********************************************************\n","steps: 40319\n","episodes: 174\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8185645\n","********************************************************\n","episode reward: -1.030000000000001\n","********************************************************\n","steps: 40499\n","episodes: 175\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8177544999999999\n","********************************************************\n","episode reward: -5.999999999999913\n","********************************************************\n","steps: 41304\n","episodes: 176\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.814132\n","********************************************************\n","episode reward: -1.5700000000000012\n","********************************************************\n","steps: 41540\n","episodes: 177\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.81307\n","********************************************************\n","episode reward: -1.0000000000000007\n","********************************************************\n","steps: 41744\n","episodes: 178\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.812152\n","********************************************************\n","episode reward: -1.4400000000000013\n","********************************************************\n","steps: 41980\n","episodes: 179\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.81109\n","********************************************************\n","episode reward: -2.5799999999999894\n","********************************************************\n","steps: 42368\n","episodes: 180\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.8093440000000001\n","********************************************************\n","episode reward: 0.15999999999999998\n","********************************************************\n","steps: 42403\n","episodes: 181\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.8091865\n","********************************************************\n","episode reward: 0.08999999999999977\n","********************************************************\n","steps: 42472\n","episodes: 182\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.808876\n","********************************************************\n","episode reward: 0.10999999999999993\n","********************************************************\n","steps: 42496\n","episodes: 183\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.8087679999999999\n","********************************************************\n","episode reward: -0.31000000000000005\n","********************************************************\n","steps: 42567\n","episodes: 184\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.8084485\n","********************************************************\n","episode reward: -0.4800000000000003\n","********************************************************\n","steps: 42693\n","episodes: 185\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8078815\n","********************************************************\n","episode reward: -1.940000000000002\n","********************************************************\n","steps: 42981\n","episodes: 186\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8065855\n","********************************************************\n","episode reward: -0.17000000000000004\n","********************************************************\n","steps: 43066\n","episodes: 187\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.806203\n","********************************************************\n","episode reward: -0.4000000000000002\n","********************************************************\n","steps: 43146\n","episodes: 188\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.805843\n","********************************************************\n","episode reward: -1.380000000000001\n","********************************************************\n","steps: 43362\n","episodes: 189\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.804871\n","********************************************************\n","episode reward: -1.0900000000000016\n","********************************************************\n","steps: 43639\n","episodes: 190\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8036245\n","********************************************************\n","episode reward: -0.05000000000000009\n","********************************************************\n","steps: 43699\n","episodes: 191\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8033545\n","********************************************************\n","episode reward: -3.3899999999999677\n","********************************************************\n","steps: 44189\n","episodes: 192\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.8011495\n","********************************************************\n","episode reward: -0.9600000000000007\n","********************************************************\n","steps: 44360\n","episodes: 193\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.80038\n","********************************************************\n","episode reward: -2.0600000000000005\n","********************************************************\n","steps: 44675\n","episodes: 194\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7989625\n","********************************************************\n","episode reward: -1.5200000000000014\n","********************************************************\n","steps: 44947\n","episodes: 195\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7977385\n","********************************************************\n","episode reward: -2.8099999999999845\n","********************************************************\n","steps: 45327\n","episodes: 196\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7960285\n","********************************************************\n","episode reward: -1.130000000000001\n","********************************************************\n","steps: 45541\n","episodes: 197\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7950655\n","********************************************************\n","episode reward: -1.8500000000000016\n","********************************************************\n","steps: 45800\n","episodes: 198\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7939\n","********************************************************\n","episode reward: -2.6799999999999873\n","********************************************************\n","steps: 46189\n","episodes: 199\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7921495\n","********************************************************\n","episode reward: -0.08000000000000015\n","********************************************************\n","steps: 46261\n","episodes: 200\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7918255\n","********************************************************\n","episode reward: -0.6700000000000006\n","********************************************************\n","steps: 46415\n","episodes: 201\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7911325\n","********************************************************\n","episode reward: -4.189999999999955\n","********************************************************\n","steps: 46975\n","episodes: 202\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7886124999999999\n","********************************************************\n","episode reward: -0.09000000000000008\n","********************************************************\n","steps: 47026\n","episodes: 203\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7883830000000001\n","********************************************************\n","episode reward: -1.8900000000000015\n","********************************************************\n","steps: 47307\n","episodes: 204\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7871185\n","********************************************************\n","episode reward: -0.9600000000000009\n","********************************************************\n","steps: 47496\n","episodes: 205\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.786268\n","********************************************************\n","episode reward: -1.8100000000000016\n","********************************************************\n","steps: 47792\n","episodes: 206\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.784936\n","********************************************************\n","episode reward: -2.6499999999999875\n","********************************************************\n","steps: 48175\n","episodes: 207\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.7832125\n","********************************************************\n","episode reward: -3.6699999999999657\n","********************************************************\n","steps: 48650\n","episodes: 208\n","mean 100 episode reward: -1.3\n","% time spent exploring: 0.781075\n","********************************************************\n","episode reward: -2.8899999999999766\n","********************************************************\n","steps: 49091\n","episodes: 209\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.7790905\n","********************************************************\n","episode reward: -1.5400000000000014\n","********************************************************\n","steps: 49347\n","episodes: 210\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.7779385\n","********************************************************\n","episode reward: -2.0100000000000016\n","********************************************************\n","steps: 49694\n","episodes: 211\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.776377\n","********************************************************\n","episode reward: -1.2200000000000013\n","********************************************************\n","steps: 49910\n","episodes: 212\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.775405\n","********************************************************\n","episode reward: -1.2000000000000013\n","********************************************************\n","steps: 50110\n","episodes: 213\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.774505\n","********************************************************\n","episode reward: -0.06999999999999995\n","********************************************************\n","steps: 50177\n","episodes: 214\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.7742034999999999\n","********************************************************\n","episode reward: -1.8400000000000014\n","********************************************************\n","steps: 50447\n","episodes: 215\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.7729885\n","********************************************************\n","episode reward: -1.140000000000001\n","********************************************************\n","steps: 50610\n","episodes: 216\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.772255\n","********************************************************\n","episode reward: -0.8700000000000009\n","********************************************************\n","steps: 50767\n","episodes: 217\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.7715485\n","********************************************************\n","episode reward: -0.8100000000000007\n","********************************************************\n","steps: 50922\n","episodes: 218\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.770851\n","********************************************************\n","episode reward: -5.789999999999921\n","********************************************************\n","steps: 51742\n","episodes: 219\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.767161\n","********************************************************\n","episode reward: -0.09000000000000002\n","********************************************************\n","steps: 51800\n","episodes: 220\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.7669\n","********************************************************\n","episode reward: -0.6300000000000004\n","********************************************************\n","steps: 51888\n","episodes: 221\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.766504\n","********************************************************\n","episode reward: -0.39000000000000024\n","********************************************************\n","steps: 51978\n","episodes: 222\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.766099\n","********************************************************\n","episode reward: -0.3800000000000003\n","********************************************************\n","steps: 52066\n","episodes: 223\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.765703\n","********************************************************\n","episode reward: -3.7399999999999647\n","********************************************************\n","steps: 52563\n","episodes: 224\n","mean 100 episode reward: -1.4\n","% time spent exploring: 0.7634664999999999\n","********************************************************\n","episode reward: -2.9199999999999755\n","********************************************************\n","steps: 53012\n","episodes: 225\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.761446\n","********************************************************\n","episode reward: -1.790000000000002\n","********************************************************\n","steps: 53323\n","episodes: 226\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.7600465000000001\n","********************************************************\n","episode reward: -2.9299999999999815\n","********************************************************\n","steps: 53737\n","episodes: 227\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.7581835\n","********************************************************\n","episode reward: -4.239999999999945\n","********************************************************\n","steps: 54309\n","episodes: 228\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.7556095\n","********************************************************\n","episode reward: -2.08\n","********************************************************\n","steps: 54597\n","episodes: 229\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.7543135000000001\n","********************************************************\n","episode reward: -0.24000000000000013\n","********************************************************\n","steps: 54636\n","episodes: 230\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.754138\n","********************************************************\n","episode reward: -1.480000000000001\n","********************************************************\n","steps: 54842\n","episodes: 231\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.753211\n","********************************************************\n","episode reward: -1.4700000000000013\n","********************************************************\n","steps: 55058\n","episodes: 232\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.752239\n","********************************************************\n","episode reward: -1.3200000000000012\n","********************************************************\n","steps: 55283\n","episodes: 233\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.7512265\n","********************************************************\n","episode reward: -0.7100000000000005\n","********************************************************\n","steps: 55415\n","episodes: 234\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.7506325\n","********************************************************\n","episode reward: -2.0000000000000018\n","********************************************************\n","steps: 55708\n","episodes: 235\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.749314\n","********************************************************\n","episode reward: -3.339999999999971\n","********************************************************\n","steps: 56165\n","episodes: 236\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.7472575\n","********************************************************\n","episode reward: -3.789999999999946\n","********************************************************\n","steps: 56786\n","episodes: 237\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.744463\n","********************************************************\n","episode reward: -7.55999999999988\n","********************************************************\n","steps: 57786\n","episodes: 238\n","mean 100 episode reward: -1.5\n","% time spent exploring: 0.7399629999999999\n","********************************************************\n","episode reward: -0.10000000000000003\n","********************************************************\n","steps: 57833\n","episodes: 239\n","mean 100 episode reward: -1.6\n","% time spent exploring: 0.7397515\n","********************************************************\n","episode reward: -2.189999999999995\n","********************************************************\n","steps: 58154\n","episodes: 240\n","mean 100 episode reward: -1.6\n","% time spent exploring: 0.738307\n","********************************************************\n","episode reward: -4.139999999999952\n","********************************************************\n","steps: 58708\n","episodes: 241\n","mean 100 episode reward: -1.6\n","% time spent exploring: 0.735814\n","********************************************************\n","episode reward: -1.1900000000000013\n","********************************************************\n","steps: 58902\n","episodes: 242\n","mean 100 episode reward: -1.6\n","% time spent exploring: 0.7349410000000001\n","********************************************************\n","episode reward: -0.7600000000000009\n","********************************************************\n","steps: 59076\n","episodes: 243\n","mean 100 episode reward: -1.6\n","% time spent exploring: 0.7341580000000001\n","********************************************************\n","episode reward: -0.8700000000000007\n","********************************************************\n","steps: 59272\n","episodes: 244\n","mean 100 episode reward: -1.6\n","% time spent exploring: 0.733276\n","********************************************************\n","episode reward: -3.1099999999999737\n","********************************************************\n","steps: 59707\n","episodes: 245\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.7313185\n","********************************************************\n","episode reward: -2.119999999999999\n","********************************************************\n","steps: 60042\n","episodes: 246\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.729811\n","********************************************************\n","episode reward: -1.7100000000000013\n","********************************************************\n","steps: 60315\n","episodes: 247\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.7285825\n","********************************************************\n","episode reward: -0.9000000000000007\n","********************************************************\n","steps: 60463\n","episodes: 248\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.7279165\n","********************************************************\n","episode reward: -1.3800000000000014\n","********************************************************\n","steps: 60684\n","episodes: 249\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.726922\n","********************************************************\n","episode reward: -2.9499999999999793\n","********************************************************\n","steps: 61100\n","episodes: 250\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.72505\n","********************************************************\n","episode reward: -1.0300000000000007\n","********************************************************\n","steps: 61263\n","episodes: 251\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.7243165\n","********************************************************\n","episode reward: -0.5100000000000003\n","********************************************************\n","steps: 61353\n","episodes: 252\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.7239115\n","********************************************************\n","episode reward: -1.270000000000001\n","********************************************************\n","steps: 61531\n","episodes: 253\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.7231105\n","********************************************************\n","episode reward: -5.259999999999928\n","********************************************************\n","steps: 62194\n","episodes: 254\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.720127\n","********************************************************\n","episode reward: -2.6599999999999824\n","********************************************************\n","steps: 62682\n","episodes: 255\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.717931\n","********************************************************\n","episode reward: -1.9400000000000017\n","********************************************************\n","steps: 62975\n","episodes: 256\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.7166125\n","********************************************************\n","episode reward: -5.2499999999999325\n","********************************************************\n","steps: 63712\n","episodes: 257\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.7132959999999999\n","********************************************************\n","episode reward: -2.3299999999999947\n","********************************************************\n","steps: 64074\n","episodes: 258\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.711667\n","********************************************************\n","episode reward: -2.3799999999999937\n","********************************************************\n","steps: 64402\n","episodes: 259\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.710191\n","********************************************************\n","episode reward: -2.1099999999999994\n","********************************************************\n","steps: 64718\n","episodes: 260\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.708769\n","********************************************************\n","episode reward: -3.7299999999999627\n","********************************************************\n","steps: 65220\n","episodes: 261\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.70651\n","********************************************************\n","episode reward: -0.3100000000000002\n","********************************************************\n","steps: 65289\n","episodes: 262\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.7061995\n","********************************************************\n","episode reward: -0.5400000000000003\n","********************************************************\n","steps: 65444\n","episodes: 263\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.705502\n","********************************************************\n","episode reward: -0.07999999999999999\n","********************************************************\n","steps: 65500\n","episodes: 264\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.7052499999999999\n","********************************************************\n","episode reward: -1.7000000000000013\n","********************************************************\n","steps: 65755\n","episodes: 265\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.7041025000000001\n","********************************************************\n","episode reward: -1.8400000000000016\n","********************************************************\n","steps: 66023\n","episodes: 266\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.7028965\n","********************************************************\n","episode reward: -1.4900000000000015\n","********************************************************\n","steps: 66279\n","episodes: 267\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.7017445\n","********************************************************\n","episode reward: -1.130000000000001\n","********************************************************\n","steps: 66473\n","episodes: 268\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.7008715\n","********************************************************\n","episode reward: -0.1500000000000001\n","********************************************************\n","steps: 66579\n","episodes: 269\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.7003945\n","********************************************************\n","episode reward: -1.6300000000000017\n","********************************************************\n","steps: 66846\n","episodes: 270\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.699193\n","********************************************************\n","episode reward: -0.760000000000001\n","********************************************************\n","steps: 67050\n","episodes: 271\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.698275\n","********************************************************\n","episode reward: -2.079999999999998\n","********************************************************\n","steps: 67342\n","episodes: 272\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.6969609999999999\n","********************************************************\n","episode reward: -1.3000000000000012\n","********************************************************\n","steps: 67552\n","episodes: 273\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.696016\n","********************************************************\n","episode reward: -0.40000000000000047\n","********************************************************\n","steps: 67663\n","episodes: 274\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.6955165000000001\n","********************************************************\n","episode reward: -2.3299999999999947\n","********************************************************\n","steps: 67966\n","episodes: 275\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.694153\n","********************************************************\n","episode reward: -1.2600000000000011\n","********************************************************\n","steps: 68163\n","episodes: 276\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.6932665\n","********************************************************\n","episode reward: -6.649999999999896\n","********************************************************\n","steps: 69049\n","episodes: 277\n","mean 100 episode reward: -1.7\n","% time spent exploring: 0.6892795\n","********************************************************\n","episode reward: -8.009999999999874\n","********************************************************\n","steps: 70049\n","episodes: 278\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.6847795000000001\n","********************************************************\n","episode reward: -1.200000000000001\n","********************************************************\n","steps: 70254\n","episodes: 279\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.6838569999999999\n","********************************************************\n","episode reward: -0.700000000000001\n","********************************************************\n","steps: 70411\n","episodes: 280\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.6831505\n","********************************************************\n","episode reward: -1.4900000000000013\n","********************************************************\n","steps: 70630\n","episodes: 281\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.6821649999999999\n","********************************************************\n","episode reward: -0.8900000000000007\n","********************************************************\n","steps: 70779\n","episodes: 282\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.6814945\n","********************************************************\n","episode reward: -0.970000000000001\n","********************************************************\n","steps: 70958\n","episodes: 283\n","mean 100 episode reward: -1.8\n","% time spent exploring: 0.680689\n","********************************************************\n","episode reward: -2.08\n","********************************************************\n","steps: 71247\n","episodes: 284\n","mean 100 episode reward: -1.9\n","% time spent exploring: 0.6793885\n","********************************************************\n","episode reward: -4.189999999999955\n","********************************************************\n","steps: 71827\n","episodes: 285\n","mean 100 episode reward: -1.9\n","% time spent exploring: 0.6767785\n","********************************************************\n","episode reward: -1.130000000000001\n","********************************************************\n","steps: 72013\n","episodes: 286\n","mean 100 episode reward: -1.9\n","% time spent exploring: 0.6759415\n","********************************************************\n","episode reward: -4.8399999999999395\n","********************************************************\n","steps: 72655\n","episodes: 287\n","mean 100 episode reward: -1.9\n","% time spent exploring: 0.6730525\n","********************************************************\n","episode reward: -1.9000000000000015\n","********************************************************\n","steps: 72968\n","episodes: 288\n","mean 100 episode reward: -1.9\n","% time spent exploring: 0.671644\n","********************************************************\n","episode reward: -1.5100000000000011\n","********************************************************\n","steps: 73229\n","episodes: 289\n","mean 100 episode reward: -2.0\n","% time spent exploring: 0.6704695\n","********************************************************\n","episode reward: -6.509999999999903\n","********************************************************\n","steps: 74069\n","episodes: 290\n","mean 100 episode reward: -2.0\n","% time spent exploring: 0.6666894999999999\n","********************************************************\n","episode reward: -2.339999999999994\n","********************************************************\n","steps: 74392\n","episodes: 291\n","mean 100 episode reward: -2.0\n","% time spent exploring: 0.6652359999999999\n","********************************************************\n","episode reward: -2.8899999999999784\n","********************************************************\n","steps: 74795\n","episodes: 292\n","mean 100 episode reward: -2.0\n","% time spent exploring: 0.6634225\n","********************************************************\n","episode reward: -0.23000000000000015\n","********************************************************\n","steps: 74896\n","episodes: 293\n","mean 100 episode reward: -2.0\n","% time spent exploring: 0.662968\n","********************************************************\n","episode reward: -2.439999999999988\n","********************************************************\n","steps: 75320\n","episodes: 294\n","mean 100 episode reward: -2.0\n","% time spent exploring: 0.66106\n","********************************************************\n","episode reward: -4.299999999999944\n","********************************************************\n","steps: 75884\n","episodes: 295\n","mean 100 episode reward: -2.0\n","% time spent exploring: 0.658522\n","********************************************************\n","episode reward: -1.6800000000000013\n","********************************************************\n","steps: 76141\n","episodes: 296\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6573655\n","********************************************************\n","episode reward: -3.609999999999958\n","********************************************************\n","steps: 76642\n","episodes: 297\n","mean 100 episode reward: -2.0\n","% time spent exploring: 0.655111\n","********************************************************\n","episode reward: -1.9200000000000017\n","********************************************************\n","steps: 76966\n","episodes: 298\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.653653\n","********************************************************\n","episode reward: -3.7899999999999636\n","********************************************************\n","steps: 77462\n","episodes: 299\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.651421\n","********************************************************\n","episode reward: -2.359999999999994\n","********************************************************\n","steps: 77782\n","episodes: 300\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.649981\n","********************************************************\n","episode reward: -2.5599999999999854\n","********************************************************\n","steps: 78201\n","episodes: 301\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6480954999999999\n","********************************************************\n","episode reward: -2.2699999999999956\n","********************************************************\n","steps: 78515\n","episodes: 302\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6466825\n","********************************************************\n","episode reward: -3.6699999999999635\n","********************************************************\n","steps: 79017\n","episodes: 303\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6444235\n","********************************************************\n","episode reward: -0.6700000000000005\n","********************************************************\n","steps: 79123\n","episodes: 304\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6439465\n","********************************************************\n","episode reward: -2.259999999999989\n","********************************************************\n","steps: 79460\n","episodes: 305\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6424300000000001\n","********************************************************\n","episode reward: -0.5600000000000005\n","********************************************************\n","steps: 79581\n","episodes: 306\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6418855\n","********************************************************\n","episode reward: -0.8500000000000008\n","********************************************************\n","steps: 79726\n","episodes: 307\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6412329999999999\n","********************************************************\n","episode reward: -6.9399999999998885\n","********************************************************\n","steps: 80591\n","episodes: 308\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6373405\n","********************************************************\n","episode reward: -0.6800000000000006\n","********************************************************\n","steps: 80718\n","episodes: 309\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6367689999999999\n","********************************************************\n","episode reward: -1.7500000000000013\n","********************************************************\n","steps: 80987\n","episodes: 310\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.6355585\n","********************************************************\n","episode reward: -7.219999999999888\n","********************************************************\n","steps: 81878\n","episodes: 311\n","mean 100 episode reward: -2.1\n","% time spent exploring: 0.631549\n","********************************************************\n","episode reward: -2.919999999999982\n","********************************************************\n","steps: 82240\n","episodes: 312\n","mean 100 episode reward: -2.2\n","% time spent exploring: 0.62992\n","********************************************************\n","episode reward: -1.8400000000000019\n","********************************************************\n","steps: 82548\n","episodes: 313\n","mean 100 episode reward: -2.2\n","% time spent exploring: 0.6285339999999999\n","********************************************************\n","episode reward: -2.1599999999999984\n","********************************************************\n","steps: 82860\n","episodes: 314\n","mean 100 episode reward: -2.2\n","% time spent exploring: 0.62713\n","********************************************************\n","episode reward: -5.139999999999933\n","********************************************************\n","steps: 83495\n","episodes: 315\n","mean 100 episode reward: -2.2\n","% time spent exploring: 0.6242725\n","********************************************************\n","episode reward: -6.429999999999906\n","********************************************************\n","steps: 84264\n","episodes: 316\n","mean 100 episode reward: -2.3\n","% time spent exploring: 0.620812\n","********************************************************\n","episode reward: -6.029999999999916\n","********************************************************\n","steps: 85045\n","episodes: 317\n","mean 100 episode reward: -2.3\n","% time spent exploring: 0.6172975\n","********************************************************\n","episode reward: -2.539999999999983\n","********************************************************\n","steps: 85418\n","episodes: 318\n","mean 100 episode reward: -2.4\n","% time spent exploring: 0.6156189999999999\n","********************************************************\n","episode reward: -0.07000000000000015\n","********************************************************\n","steps: 85485\n","episodes: 319\n","mean 100 episode reward: -2.4\n","% time spent exploring: 0.6153175\n","********************************************************\n","episode reward: -4.539999999999937\n","********************************************************\n","steps: 86074\n","episodes: 320\n","mean 100 episode reward: -2.3\n","% time spent exploring: 0.6126670000000001\n","********************************************************\n","episode reward: -6.309999999999907\n","********************************************************\n","steps: 86833\n","episodes: 321\n","mean 100 episode reward: -2.4\n","% time spent exploring: 0.6092515\n","********************************************************\n","episode reward: -3.5599999999999685\n","********************************************************\n","steps: 87345\n","episodes: 322\n","mean 100 episode reward: -2.4\n","% time spent exploring: 0.6069475\n","********************************************************\n","episode reward: -1.020000000000001\n","********************************************************\n","steps: 87504\n","episodes: 323\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.606232\n","********************************************************\n","episode reward: -0.8800000000000008\n","********************************************************\n","steps: 87685\n","episodes: 324\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.6054174999999999\n","********************************************************\n","episode reward: -4.059999999999956\n","********************************************************\n","steps: 88196\n","episodes: 325\n","mean 100 episode reward: -2.4\n","% time spent exploring: 0.603118\n","********************************************************\n","episode reward: -7.479999999999881\n","********************************************************\n","steps: 89100\n","episodes: 326\n","mean 100 episode reward: -2.4\n","% time spent exploring: 0.59905\n","********************************************************\n","episode reward: -1.020000000000001\n","********************************************************\n","steps: 89270\n","episodes: 327\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.598285\n","********************************************************\n","episode reward: -2.5199999999999907\n","********************************************************\n","steps: 89619\n","episodes: 328\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.5967145\n","********************************************************\n","episode reward: -0.19000000000000014\n","********************************************************\n","steps: 89689\n","episodes: 329\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.5963995\n","********************************************************\n","episode reward: -0.5700000000000005\n","********************************************************\n","steps: 89826\n","episodes: 330\n","mean 100 episode reward: -2.4\n","% time spent exploring: 0.595783\n","********************************************************\n","episode reward: -1.3200000000000012\n","********************************************************\n","steps: 90028\n","episodes: 331\n","mean 100 episode reward: -2.4\n","% time spent exploring: 0.594874\n","********************************************************\n","episode reward: -1.9100000000000017\n","********************************************************\n","steps: 90293\n","episodes: 332\n","mean 100 episode reward: -2.4\n","% time spent exploring: 0.5936815\n","********************************************************\n","episode reward: -5.199999999999929\n","********************************************************\n","steps: 90951\n","episodes: 333\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.5907205\n","********************************************************\n","episode reward: -3.7199999999999647\n","********************************************************\n","steps: 91404\n","episodes: 334\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.5886819999999999\n","********************************************************\n","episode reward: -5.5299999999999265\n","********************************************************\n","steps: 92134\n","episodes: 335\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.585397\n","********************************************************\n","episode reward: -3.619999999999967\n","********************************************************\n","steps: 92589\n","episodes: 336\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5833495\n","********************************************************\n","episode reward: -2.319999999999995\n","********************************************************\n","steps: 92889\n","episodes: 337\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5819995\n","********************************************************\n","episode reward: -4.189999999999951\n","********************************************************\n","steps: 93418\n","episodes: 338\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.579619\n","********************************************************\n","episode reward: -1.6600000000000013\n","********************************************************\n","steps: 93675\n","episodes: 339\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.5784625\n","********************************************************\n","episode reward: -3.669999999999964\n","********************************************************\n","steps: 94131\n","episodes: 340\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.5764104999999999\n","********************************************************\n","episode reward: -2.679999999999987\n","********************************************************\n","steps: 94492\n","episodes: 341\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.574786\n","********************************************************\n","episode reward: -2.599999999999987\n","********************************************************\n","steps: 94888\n","episodes: 342\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.5730040000000001\n","********************************************************\n","episode reward: -1.9400000000000017\n","********************************************************\n","steps: 95206\n","episodes: 343\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.571573\n","********************************************************\n","episode reward: 0.09999999999999985\n","********************************************************\n","steps: 95293\n","episodes: 344\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5711815\n","********************************************************\n","episode reward: -1.4700000000000013\n","********************************************************\n","steps: 95494\n","episodes: 345\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.5702769999999999\n","********************************************************\n","episode reward: -5.0399999999999325\n","********************************************************\n","steps: 96126\n","episodes: 346\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.567433\n","********************************************************\n","episode reward: -0.7600000000000006\n","********************************************************\n","steps: 96242\n","episodes: 347\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5669109999999999\n","********************************************************\n","episode reward: -5.859999999999918\n","********************************************************\n","steps: 96947\n","episodes: 348\n","mean 100 episode reward: -2.5\n","% time spent exploring: 0.5637384999999999\n","********************************************************\n","episode reward: -1.4800000000000015\n","********************************************************\n","steps: 97209\n","episodes: 349\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5625595\n","********************************************************\n","episode reward: -2.8199999999999843\n","********************************************************\n","steps: 97613\n","episodes: 350\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5607415\n","********************************************************\n","episode reward: -1.9400000000000015\n","********************************************************\n","steps: 97884\n","episodes: 351\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.559522\n","********************************************************\n","episode reward: -4.089999999999954\n","********************************************************\n","steps: 98400\n","episodes: 352\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5571999999999999\n","********************************************************\n","episode reward: -4.279999999999953\n","********************************************************\n","steps: 98954\n","episodes: 353\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5547070000000001\n","********************************************************\n","episode reward: -1.9600000000000017\n","********************************************************\n","steps: 99228\n","episodes: 354\n","mean 100 episode reward: -2.7\n","% time spent exploring: 0.553474\n","********************************************************\n","episode reward: -2.969999999999976\n","********************************************************\n","steps: 99637\n","episodes: 355\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5516335\n","********************************************************\n","episode reward: -3.6499999999999653\n","********************************************************\n","steps: 100095\n","episodes: 356\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5495725\n","********************************************************\n","episode reward: -3.0399999999999796\n","********************************************************\n","steps: 100540\n","episodes: 357\n","mean 100 episode reward: -2.7\n","% time spent exploring: 0.5475699999999999\n","********************************************************\n","episode reward: -1.010000000000001\n","********************************************************\n","steps: 100708\n","episodes: 358\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.546814\n","********************************************************\n","episode reward: -2.0700000000000003\n","********************************************************\n","steps: 100982\n","episodes: 359\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5455810000000001\n","********************************************************\n","episode reward: -2.6799999999999873\n","********************************************************\n","steps: 101343\n","episodes: 360\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5439565\n","********************************************************\n","episode reward: -0.4300000000000005\n","********************************************************\n","steps: 101452\n","episodes: 361\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.543466\n","********************************************************\n","episode reward: -1.5900000000000014\n","********************************************************\n","steps: 101729\n","episodes: 362\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5422195\n","********************************************************\n","episode reward: -3.6299999999999604\n","********************************************************\n","steps: 102251\n","episodes: 363\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5398704999999999\n","********************************************************\n","episode reward: -2.3299999999999943\n","********************************************************\n","steps: 102574\n","episodes: 364\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.5384169999999999\n","********************************************************\n","episode reward: -0.15000000000000005\n","********************************************************\n","steps: 102639\n","episodes: 365\n","mean 100 episode reward: -2.7\n","% time spent exploring: 0.5381245\n","********************************************************\n","episode reward: -1.4800000000000013\n","********************************************************\n","steps: 102894\n","episodes: 366\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.536977\n","********************************************************\n","episode reward: -8.309999999999858\n","********************************************************\n","steps: 103894\n","episodes: 367\n","mean 100 episode reward: -2.6\n","% time spent exploring: 0.532477\n","********************************************************\n","episode reward: -1.2900000000000011\n","********************************************************\n","steps: 104084\n","episodes: 368\n","mean 100 episode reward: -2.7\n","% time spent exploring: 0.531622\n","********************************************************\n","episode reward: -3.429999999999969\n","********************************************************\n","steps: 104529\n","episodes: 369\n","mean 100 episode reward: -2.7\n","% time spent exploring: 0.5296194999999999\n","********************************************************\n","episode reward: -4.389999999999951\n","********************************************************\n","steps: 105080\n","episodes: 370\n","mean 100 episode reward: -2.7\n","% time spent exploring: 0.5271399999999999\n","********************************************************\n","episode reward: -2.599999999999989\n","********************************************************\n","steps: 105454\n","episodes: 371\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.525457\n","********************************************************\n","episode reward: -0.15000000000000052\n","********************************************************\n","steps: 105587\n","episodes: 372\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.5248584999999999\n","********************************************************\n","episode reward: -4.499999999999947\n","********************************************************\n","steps: 106145\n","episodes: 373\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.5223475\n","********************************************************\n","episode reward: -3.6199999999999672\n","********************************************************\n","steps: 106651\n","episodes: 374\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.5200704999999999\n","********************************************************\n","episode reward: -2.7199999999999864\n","********************************************************\n","steps: 107006\n","episodes: 375\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.518473\n","********************************************************\n","episode reward: -4.6399999999999455\n","********************************************************\n","steps: 107562\n","episodes: 376\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.515971\n","********************************************************\n","episode reward: -2.3899999999999935\n","********************************************************\n","steps: 107887\n","episodes: 377\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.5145085\n","********************************************************\n","episode reward: -0.3400000000000004\n","********************************************************\n","steps: 108012\n","episodes: 378\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.513946\n","********************************************************\n","episode reward: -5.099999999999936\n","********************************************************\n","steps: 108677\n","episodes: 379\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.5109535000000001\n","********************************************************\n","episode reward: -2.349999999999994\n","********************************************************\n","steps: 108986\n","episodes: 380\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.509563\n","********************************************************\n","episode reward: -5.929999999999918\n","********************************************************\n","steps: 109708\n","episodes: 381\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.5063139999999999\n","********************************************************\n","episode reward: -0.3800000000000003\n","********************************************************\n","steps: 109795\n","episodes: 382\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.5059225\n","********************************************************\n","episode reward: -1.8500000000000014\n","********************************************************\n","steps: 110075\n","episodes: 383\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.5046625\n","********************************************************\n","episode reward: -1.140000000000001\n","********************************************************\n","steps: 110262\n","episodes: 384\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.5038210000000001\n","********************************************************\n","episode reward: -2.3899999999999935\n","********************************************************\n","steps: 110606\n","episodes: 385\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.502273\n","********************************************************\n","episode reward: -1.8400000000000014\n","********************************************************\n","steps: 110882\n","episodes: 386\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.501031\n","********************************************************\n","episode reward: -6.599999999999898\n","********************************************************\n","steps: 111709\n","episodes: 387\n","mean 100 episode reward: -2.8\n","% time spent exploring: 0.49730950000000007\n","********************************************************\n","episode reward: -1.9000000000000017\n","********************************************************\n","steps: 111998\n","episodes: 388\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.49600900000000003\n","********************************************************\n","episode reward: -8.249999999999861\n","********************************************************\n","steps: 112998\n","episodes: 389\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.491509\n","********************************************************\n","episode reward: -8.409999999999862\n","********************************************************\n","steps: 113998\n","episodes: 390\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.487009\n","********************************************************\n","episode reward: -1.090000000000001\n","********************************************************\n","steps: 114162\n","episodes: 391\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.4862709999999999\n","********************************************************\n","episode reward: -4.41999999999995\n","********************************************************\n","steps: 114734\n","episodes: 392\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.48369699999999993\n","********************************************************\n","episode reward: -1.8200000000000016\n","********************************************************\n","steps: 115038\n","episodes: 393\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.482329\n","********************************************************\n","episode reward: -1.2400000000000009\n","********************************************************\n","steps: 115210\n","episodes: 394\n","mean 100 episode reward: -3.0\n","% time spent exploring: 0.48155500000000007\n","********************************************************\n","episode reward: -2.509999999999991\n","********************************************************\n","steps: 115608\n","episodes: 395\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.47976399999999997\n","********************************************************\n","episode reward: -4.199999999999953\n","********************************************************\n","steps: 116130\n","episodes: 396\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.47741500000000003\n","********************************************************\n","episode reward: -3.449999999999971\n","********************************************************\n","steps: 116620\n","episodes: 397\n","mean 100 episode reward: -3.0\n","% time spent exploring: 0.47521\n","********************************************************\n","episode reward: -1.3400000000000012\n","********************************************************\n","steps: 116814\n","episodes: 398\n","mean 100 episode reward: -3.0\n","% time spent exploring: 0.474337\n","********************************************************\n","episode reward: -6.339999999999909\n","********************************************************\n","steps: 117558\n","episodes: 399\n","mean 100 episode reward: -2.9\n","% time spent exploring: 0.470989\n","********************************************************\n","episode reward: -3.1699999999999724\n","********************************************************\n","steps: 117978\n","episodes: 400\n","mean 100 episode reward: -3.0\n","% time spent exploring: 0.46909899999999993\n","********************************************************\n","episode reward: -7.069999999999892\n","********************************************************\n","steps: 118797\n","episodes: 401\n","mean 100 episode reward: -3.0\n","% time spent exploring: 0.46541350000000004\n","********************************************************\n","episode reward: -1.7400000000000015\n","********************************************************\n","steps: 119061\n","episodes: 402\n","mean 100 episode reward: -3.0\n","% time spent exploring: 0.46422549999999996\n","********************************************************\n","episode reward: -6.839999999999889\n","********************************************************\n","steps: 119907\n","episodes: 403\n","mean 100 episode reward: -3.0\n","% time spent exploring: 0.46041849999999995\n","********************************************************\n","episode reward: -2.5799999999999894\n","********************************************************\n","steps: 120276\n","episodes: 404\n","mean 100 episode reward: -3.0\n","% time spent exploring: 0.458758\n","********************************************************\n","episode reward: -6.979999999999896\n","********************************************************\n","steps: 121108\n","episodes: 405\n","mean 100 episode reward: -3.1\n","% time spent exploring: 0.45501400000000003\n","********************************************************\n","episode reward: -1.8300000000000014\n","********************************************************\n","steps: 121377\n","episodes: 406\n","mean 100 episode reward: -3.1\n","% time spent exploring: 0.4538035\n","********************************************************\n","episode reward: -0.5200000000000004\n","********************************************************\n","steps: 121480\n","episodes: 407\n","mean 100 episode reward: -3.1\n","% time spent exploring: 0.45333999999999997\n","********************************************************\n","episode reward: -5.789999999999919\n","********************************************************\n","steps: 122173\n","episodes: 408\n","mean 100 episode reward: -3.1\n","% time spent exploring: 0.45022149999999994\n","********************************************************\n","episode reward: -3.689999999999961\n","********************************************************\n","steps: 122624\n","episodes: 409\n","mean 100 episode reward: -3.1\n","% time spent exploring: 0.44819200000000003\n","********************************************************\n","episode reward: -7.319999999999888\n","********************************************************\n","steps: 123474\n","episodes: 410\n","mean 100 episode reward: -3.1\n","% time spent exploring: 0.44436699999999996\n","********************************************************\n","episode reward: -2.08\n","********************************************************\n","steps: 123780\n","episodes: 411\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.44299\n","********************************************************\n","episode reward: -5.509999999999927\n","********************************************************\n","steps: 124468\n","episodes: 412\n","mean 100 episode reward: -3.1\n","% time spent exploring: 0.439894\n","********************************************************\n","episode reward: -6.929999999999893\n","********************************************************\n","steps: 125289\n","episodes: 413\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.43619949999999996\n","********************************************************\n","episode reward: -4.119999999999955\n","********************************************************\n","steps: 125822\n","episodes: 414\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.433801\n","********************************************************\n","episode reward: -2.1599999999999984\n","********************************************************\n","steps: 126133\n","episodes: 415\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.4324015\n","********************************************************\n","episode reward: -3.9599999999999578\n","********************************************************\n","steps: 126642\n","episodes: 416\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.4301109999999999\n","********************************************************\n","episode reward: -7.949999999999866\n","********************************************************\n","steps: 127582\n","episodes: 417\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.42588099999999995\n","********************************************************\n","episode reward: -2.8099999999999845\n","********************************************************\n","steps: 127969\n","episodes: 418\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.4241395\n","********************************************************\n","episode reward: -2.259999999999994\n","********************************************************\n","steps: 128302\n","episodes: 419\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.42264099999999993\n","********************************************************\n","episode reward: -7.059999999999892\n","********************************************************\n","steps: 129140\n","episodes: 420\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.41886999999999996\n","********************************************************\n","episode reward: -3.039999999999979\n","********************************************************\n","steps: 129507\n","episodes: 421\n","mean 100 episode reward: -3.3\n","% time spent exploring: 0.41721850000000005\n","********************************************************\n","episode reward: -1.030000000000001\n","********************************************************\n","steps: 129689\n","episodes: 422\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.4163994999999999\n","********************************************************\n","episode reward: -4.679999999999945\n","********************************************************\n","steps: 130308\n","episodes: 423\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.4136139999999999\n","********************************************************\n","episode reward: -3.7499999999999645\n","********************************************************\n","steps: 130815\n","episodes: 424\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.4113325\n","********************************************************\n","episode reward: -1.6500000000000017\n","********************************************************\n","steps: 131071\n","episodes: 425\n","mean 100 episode reward: -3.3\n","% time spent exploring: 0.41018049999999995\n","********************************************************\n","episode reward: -3.159999999999977\n","********************************************************\n","steps: 131488\n","episodes: 426\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.408304\n","********************************************************\n","episode reward: -4.129999999999956\n","********************************************************\n","steps: 132005\n","episodes: 427\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.4059775\n","********************************************************\n","episode reward: -8.429999999999863\n","********************************************************\n","steps: 133005\n","episodes: 428\n","mean 100 episode reward: -3.2\n","% time spent exploring: 0.40147750000000004\n","********************************************************\n","episode reward: -6.29999999999991\n","********************************************************\n","steps: 133755\n","episodes: 429\n","mean 100 episode reward: -3.3\n","% time spent exploring: 0.3981025\n","********************************************************\n","episode reward: -6.739999999999901\n","********************************************************\n","steps: 134536\n","episodes: 430\n","mean 100 episode reward: -3.4\n","% time spent exploring: 0.39458800000000005\n","********************************************************\n","episode reward: -0.19000000000000017\n","********************************************************\n","steps: 134606\n","episodes: 431\n","mean 100 episode reward: -3.4\n","% time spent exploring: 0.394273\n","********************************************************\n","episode reward: -4.019999999999959\n","********************************************************\n","steps: 135077\n","episodes: 432\n","mean 100 episode reward: -3.4\n","% time spent exploring: 0.39215349999999993\n","********************************************************\n","episode reward: -7.5599999999998815\n","********************************************************\n","steps: 135973\n","episodes: 433\n","mean 100 episode reward: -3.4\n","% time spent exploring: 0.3881214999999999\n","********************************************************\n","episode reward: -3.439999999999971\n","********************************************************\n","steps: 136424\n","episodes: 434\n","mean 100 episode reward: -3.4\n","% time spent exploring: 0.386092\n","********************************************************\n","episode reward: -8.47999999999986\n","********************************************************\n","steps: 137407\n","episodes: 435\n","mean 100 episode reward: -3.4\n","% time spent exploring: 0.3816685000000001\n","********************************************************\n","episode reward: -6.259999999999909\n","********************************************************\n","steps: 138201\n","episodes: 436\n","mean 100 episode reward: -3.5\n","% time spent exploring: 0.37809550000000003\n","********************************************************\n","episode reward: -2.539999999999986\n","********************************************************\n","steps: 138558\n","episodes: 437\n","mean 100 episode reward: -3.5\n","% time spent exploring: 0.37648899999999996\n","********************************************************\n","episode reward: -7.819999999999868\n","********************************************************\n","steps: 139477\n","episodes: 438\n","mean 100 episode reward: -3.5\n","% time spent exploring: 0.3723535\n","********************************************************\n","episode reward: -0.9000000000000011\n","********************************************************\n","steps: 139652\n","episodes: 439\n","mean 100 episode reward: -3.5\n","% time spent exploring: 0.37156599999999995\n","********************************************************\n","episode reward: -1.5100000000000011\n","********************************************************\n","steps: 139862\n","episodes: 440\n","mean 100 episode reward: -3.5\n","% time spent exploring: 0.370621\n","********************************************************\n","episode reward: -2.569999999999989\n","********************************************************\n","steps: 140189\n","episodes: 441\n","mean 100 episode reward: -3.5\n","% time spent exploring: 0.3691494999999999\n","********************************************************\n","episode reward: -8.629999999999857\n","********************************************************\n","steps: 141189\n","episodes: 442\n","mean 100 episode reward: -3.5\n","% time spent exploring: 0.36464949999999996\n","********************************************************\n","episode reward: -2.6599999999999877\n","********************************************************\n","steps: 141561\n","episodes: 443\n","mean 100 episode reward: -3.6\n","% time spent exploring: 0.3629755\n","********************************************************\n","episode reward: -3.8999999999999586\n","********************************************************\n","steps: 142083\n","episodes: 444\n","mean 100 episode reward: -3.6\n","% time spent exploring: 0.36062649999999996\n","********************************************************\n","episode reward: -0.9700000000000009\n","********************************************************\n","steps: 142240\n","episodes: 445\n","mean 100 episode reward: -3.6\n","% time spent exploring: 0.3599199999999999\n","********************************************************\n","episode reward: -2.5299999999999883\n","********************************************************\n","steps: 142543\n","episodes: 446\n","mean 100 episode reward: -3.6\n","% time spent exploring: 0.35855649999999994\n","********************************************************\n","episode reward: -1.8700000000000017\n","********************************************************\n","steps: 142796\n","episodes: 447\n","mean 100 episode reward: -3.6\n","% time spent exploring: 0.357418\n","********************************************************\n","episode reward: -6.559999999999905\n","********************************************************\n","steps: 143551\n","episodes: 448\n","mean 100 episode reward: -3.6\n","% time spent exploring: 0.35402049999999996\n","********************************************************\n","episode reward: -5.8299999999999175\n","********************************************************\n","steps: 144217\n","episodes: 449\n","mean 100 episode reward: -3.6\n","% time spent exploring: 0.35102350000000004\n","********************************************************\n","episode reward: -5.629999999999919\n","********************************************************\n","steps: 144887\n","episodes: 450\n","mean 100 episode reward: -3.6\n","% time spent exploring: 0.34800849999999994\n","********************************************************\n","episode reward: -2.90999999999998\n","********************************************************\n","steps: 145258\n","episodes: 451\n","mean 100 episode reward: -3.7\n","% time spent exploring: 0.34633899999999995\n","********************************************************\n","episode reward: -3.589999999999968\n","********************************************************\n","steps: 145694\n","episodes: 452\n","mean 100 episode reward: -3.7\n","% time spent exploring: 0.34437700000000004\n","********************************************************\n","episode reward: -4.289999999999953\n","********************************************************\n","steps: 146242\n","episodes: 453\n","mean 100 episode reward: -3.7\n","% time spent exploring: 0.34191099999999996\n","********************************************************\n","episode reward: -4.749999999999941\n","********************************************************\n","steps: 146810\n","episodes: 454\n","mean 100 episode reward: -3.7\n","% time spent exploring: 0.33935499999999996\n","********************************************************\n","episode reward: -8.789999999999852\n","********************************************************\n","steps: 147810\n","episodes: 455\n","mean 100 episode reward: -3.7\n","% time spent exploring: 0.334855\n","********************************************************\n","episode reward: -5.209999999999932\n","********************************************************\n","steps: 148421\n","episodes: 456\n","mean 100 episode reward: -3.8\n","% time spent exploring: 0.33210549999999994\n","********************************************************\n","episode reward: -0.5200000000000004\n","********************************************************\n","steps: 148524\n","episodes: 457\n","mean 100 episode reward: -3.8\n","% time spent exploring: 0.331642\n","********************************************************\n","episode reward: -7.429999999999882\n","********************************************************\n","steps: 149390\n","episodes: 458\n","mean 100 episode reward: -3.8\n","% time spent exploring: 0.32774499999999995\n","********************************************************\n","episode reward: -5.759999999999922\n","********************************************************\n","steps: 150080\n","episodes: 459\n","mean 100 episode reward: -3.8\n","% time spent exploring: 0.32464000000000004\n","********************************************************\n","episode reward: -4.9199999999999395\n","********************************************************\n","steps: 150654\n","episodes: 460\n","mean 100 episode reward: -3.9\n","% time spent exploring: 0.32205700000000004\n","********************************************************\n","episode reward: -3.2999999999999696\n","********************************************************\n","steps: 151077\n","episodes: 461\n","mean 100 episode reward: -3.9\n","% time spent exploring: 0.3201535\n","********************************************************\n","episode reward: -5.049999999999937\n","********************************************************\n","steps: 151671\n","episodes: 462\n","mean 100 episode reward: -3.9\n","% time spent exploring: 0.31748049999999994\n","********************************************************\n","episode reward: -1.270000000000001\n","********************************************************\n","steps: 151847\n","episodes: 463\n","mean 100 episode reward: -3.9\n","% time spent exploring: 0.31668850000000004\n","********************************************************\n","episode reward: -3.7799999999999616\n","********************************************************\n","steps: 152335\n","episodes: 464\n","mean 100 episode reward: -3.9\n","% time spent exploring: 0.31449249999999995\n","********************************************************\n","episode reward: -1.340000000000001\n","********************************************************\n","steps: 152526\n","episodes: 465\n","mean 100 episode reward: -3.9\n","% time spent exploring: 0.31363299999999994\n","********************************************************\n","episode reward: -8.93999999999985\n","********************************************************\n","steps: 153526\n","episodes: 466\n","mean 100 episode reward: -3.9\n","% time spent exploring: 0.309133\n","********************************************************\n","episode reward: -1.8800000000000017\n","********************************************************\n","steps: 153795\n","episodes: 467\n","mean 100 episode reward: -4.0\n","% time spent exploring: 0.3079225\n","********************************************************\n","episode reward: -1.6300000000000014\n","********************************************************\n","steps: 154026\n","episodes: 468\n","mean 100 episode reward: -4.0\n","% time spent exploring: 0.306883\n","********************************************************\n","episode reward: -8.689999999999857\n","********************************************************\n","steps: 155026\n","episodes: 469\n","mean 100 episode reward: -4.0\n","% time spent exploring: 0.30238299999999996\n","********************************************************\n","episode reward: -3.679999999999966\n","********************************************************\n","steps: 155494\n","episodes: 470\n","mean 100 episode reward: -4.0\n","% time spent exploring: 0.300277\n","********************************************************\n","episode reward: -5.529999999999925\n","********************************************************\n","steps: 156152\n","episodes: 471\n","mean 100 episode reward: -4.0\n","% time spent exploring: 0.297316\n","********************************************************\n","episode reward: -2.8099999999999845\n","********************************************************\n","steps: 156502\n","episodes: 472\n","mean 100 episode reward: -4.0\n","% time spent exploring: 0.2957409999999999\n","********************************************************\n","episode reward: -3.589999999999965\n","********************************************************\n","steps: 156951\n","episodes: 473\n","mean 100 episode reward: -4.1\n","% time spent exploring: 0.29372050000000005\n","********************************************************\n","episode reward: -2.8999999999999826\n","********************************************************\n","steps: 157314\n","episodes: 474\n","mean 100 episode reward: -4.1\n","% time spent exploring: 0.292087\n","********************************************************\n","episode reward: -5.379999999999928\n","********************************************************\n","steps: 157926\n","episodes: 475\n","mean 100 episode reward: -4.0\n","% time spent exploring: 0.28933299999999995\n","********************************************************\n","episode reward: -3.299999999999974\n","********************************************************\n","steps: 158324\n","episodes: 476\n","mean 100 episode reward: -4.1\n","% time spent exploring: 0.28754199999999996\n","********************************************************\n","episode reward: -5.36999999999993\n","********************************************************\n","steps: 158938\n","episodes: 477\n","mean 100 episode reward: -4.1\n","% time spent exploring: 0.284779\n","********************************************************\n","episode reward: -8.45999999999986\n","********************************************************\n","steps: 159938\n","episodes: 478\n","mean 100 episode reward: -4.1\n","% time spent exploring: 0.28027899999999994\n","********************************************************\n","episode reward: -8.329999999999863\n","********************************************************\n","steps: 160916\n","episodes: 479\n","mean 100 episode reward: -4.2\n","% time spent exploring: 0.27587800000000007\n","********************************************************\n","episode reward: -7.179999999999887\n","********************************************************\n","steps: 161726\n","episodes: 480\n","mean 100 episode reward: -4.2\n","% time spent exploring: 0.27223300000000006\n","********************************************************\n","episode reward: -2.719999999999984\n","********************************************************\n","steps: 162049\n","episodes: 481\n","mean 100 episode reward: -4.2\n","% time spent exploring: 0.27077949999999995\n","********************************************************\n","episode reward: -8.529999999999859\n","********************************************************\n","steps: 163049\n","episodes: 482\n","mean 100 episode reward: -4.2\n","% time spent exploring: 0.2662795\n","********************************************************\n","episode reward: -1.170000000000001\n","********************************************************\n","steps: 163215\n","episodes: 483\n","mean 100 episode reward: -4.3\n","% time spent exploring: 0.26553249999999995\n","********************************************************\n","episode reward: -2.269999999999996\n","********************************************************\n","steps: 163527\n","episodes: 484\n","mean 100 episode reward: -4.3\n","% time spent exploring: 0.2641285\n","********************************************************\n","episode reward: -4.989999999999938\n","********************************************************\n","steps: 164097\n","episodes: 485\n","mean 100 episode reward: -4.3\n","% time spent exploring: 0.26156349999999995\n","********************************************************\n","episode reward: -8.739999999999858\n","********************************************************\n","steps: 165097\n","episodes: 486\n","mean 100 episode reward: -4.3\n","% time spent exploring: 0.2570635\n","********************************************************\n","episode reward: -5.269999999999928\n","********************************************************\n","steps: 165752\n","episodes: 487\n","mean 100 episode reward: -4.4\n","% time spent exploring: 0.2541159999999999\n","********************************************************\n","episode reward: -2.949999999999981\n","********************************************************\n","steps: 166108\n","episodes: 488\n","mean 100 episode reward: -4.4\n","% time spent exploring: 0.252514\n","********************************************************\n","episode reward: -4.189999999999953\n","********************************************************\n","steps: 166586\n","episodes: 489\n","mean 100 episode reward: -4.4\n","% time spent exploring: 0.250363\n","********************************************************\n","episode reward: -8.569999999999855\n","********************************************************\n","steps: 167586\n","episodes: 490\n","mean 100 episode reward: -4.4\n","% time spent exploring: 0.24586300000000005\n","********************************************************\n","episode reward: -8.99999999999985\n","********************************************************\n","steps: 168586\n","episodes: 491\n","mean 100 episode reward: -4.4\n","% time spent exploring: 0.241363\n","********************************************************\n","episode reward: -8.769999999999852\n","********************************************************\n","steps: 169586\n","episodes: 492\n","mean 100 episode reward: -4.4\n","% time spent exploring: 0.23686300000000005\n","********************************************************\n","episode reward: -8.919999999999852\n","********************************************************\n","steps: 170586\n","episodes: 493\n","mean 100 episode reward: -4.5\n","% time spent exploring: 0.232363\n","********************************************************\n","episode reward: -7.8399999999998755\n","********************************************************\n","steps: 171506\n","episodes: 494\n","mean 100 episode reward: -4.5\n","% time spent exploring: 0.22822299999999995\n","********************************************************\n","episode reward: -3.2299999999999756\n","********************************************************\n","steps: 171895\n","episodes: 495\n","mean 100 episode reward: -4.6\n","% time spent exploring: 0.22647249999999997\n","********************************************************\n","episode reward: -8.729999999999851\n","********************************************************\n","steps: 172895\n","episodes: 496\n","mean 100 episode reward: -4.6\n","% time spent exploring: 0.22197250000000002\n","********************************************************\n","episode reward: -8.449999999999864\n","********************************************************\n","steps: 173838\n","episodes: 497\n","mean 100 episode reward: -4.7\n","% time spent exploring: 0.21772899999999995\n","********************************************************\n","episode reward: -9.179999999999849\n","********************************************************\n","steps: 174838\n","episodes: 498\n","mean 100 episode reward: -4.7\n","% time spent exploring: 0.213229\n","********************************************************\n","episode reward: -2.0300000000000007\n","********************************************************\n","steps: 175109\n","episodes: 499\n","mean 100 episode reward: -4.8\n","% time spent exploring: 0.21200949999999996\n","********************************************************\n","episode reward: -1.020000000000001\n","********************************************************\n","steps: 175247\n","episodes: 500\n","mean 100 episode reward: -4.8\n","% time spent exploring: 0.21138849999999998\n","********************************************************\n","episode reward: -4.299999999999953\n","********************************************************\n","steps: 175794\n","episodes: 501\n","mean 100 episode reward: -4.7\n","% time spent exploring: 0.20892699999999997\n","********************************************************\n","episode reward: -8.789999999999857\n","********************************************************\n","steps: 176794\n","episodes: 502\n","mean 100 episode reward: -4.7\n","% time spent exploring: 0.20442699999999991\n","********************************************************\n","episode reward: -4.669999999999943\n","********************************************************\n","steps: 177340\n","episodes: 503\n","mean 100 episode reward: -4.8\n","% time spent exploring: 0.20196999999999998\n","********************************************************\n","episode reward: -4.529999999999948\n","********************************************************\n","steps: 177874\n","episodes: 504\n","mean 100 episode reward: -4.8\n","% time spent exploring: 0.19956699999999994\n","********************************************************\n","episode reward: -6.039999999999913\n","********************************************************\n","steps: 178553\n","episodes: 505\n","mean 100 episode reward: -4.8\n","% time spent exploring: 0.19651149999999995\n","********************************************************\n","episode reward: -6.039999999999916\n","********************************************************\n","steps: 179233\n","episodes: 506\n","mean 100 episode reward: -4.8\n","% time spent exploring: 0.1934515\n","********************************************************\n","episode reward: -8.94999999999985\n","********************************************************\n","steps: 180233\n","episodes: 507\n","mean 100 episode reward: -4.8\n","% time spent exploring: 0.18895149999999994\n","********************************************************\n","episode reward: -8.969999999999851\n","********************************************************\n","steps: 181233\n","episodes: 508\n","mean 100 episode reward: -4.9\n","% time spent exploring: 0.1844515\n","********************************************************\n","episode reward: -4.759999999999943\n","********************************************************\n","steps: 181778\n","episodes: 509\n","mean 100 episode reward: -4.9\n","% time spent exploring: 0.18199900000000002\n","********************************************************\n","episode reward: -8.759999999999849\n","********************************************************\n","steps: 182778\n","episodes: 510\n","mean 100 episode reward: -4.9\n","% time spent exploring: 0.17749899999999996\n","********************************************************\n","episode reward: -8.919999999999847\n","********************************************************\n","steps: 183778\n","episodes: 511\n","mean 100 episode reward: -4.9\n","% time spent exploring: 0.172999\n","********************************************************\n","episode reward: -8.849999999999847\n","********************************************************\n","steps: 184778\n","episodes: 512\n","mean 100 episode reward: -5.0\n","% time spent exploring: 0.16849899999999995\n","********************************************************\n","episode reward: -9.109999999999848\n","********************************************************\n","steps: 185775\n","episodes: 513\n","mean 100 episode reward: -5.0\n","% time spent exploring: 0.1640125\n","********************************************************\n","episode reward: -8.78999999999985\n","********************************************************\n","steps: 186775\n","episodes: 514\n","mean 100 episode reward: -5.1\n","% time spent exploring: 0.15951249999999995\n","********************************************************\n","episode reward: -4.089999999999952\n","********************************************************\n","steps: 187273\n","episodes: 515\n","mean 100 episode reward: -5.1\n","% time spent exploring: 0.1572715\n","********************************************************\n","episode reward: -8.929999999999854\n","********************************************************\n","steps: 188273\n","episodes: 516\n","mean 100 episode reward: -5.1\n","% time spent exploring: 0.15277149999999995\n","********************************************************\n","episode reward: -9.259999999999843\n","********************************************************\n","steps: 189273\n","episodes: 517\n","mean 100 episode reward: -5.2\n","% time spent exploring: 0.1482715\n","********************************************************\n","episode reward: -9.089999999999847\n","********************************************************\n","steps: 190273\n","episodes: 518\n","mean 100 episode reward: -5.2\n","% time spent exploring: 0.14377149999999994\n","********************************************************\n","episode reward: -9.029999999999848\n","********************************************************\n","steps: 191273\n","episodes: 519\n","mean 100 episode reward: -5.3\n","% time spent exploring: 0.1392715\n","********************************************************\n","episode reward: -7.0099999999998905\n","********************************************************\n","steps: 192049\n","episodes: 520\n","mean 100 episode reward: -5.3\n","% time spent exploring: 0.13577949999999994\n","********************************************************\n","episode reward: -8.75999999999985\n","********************************************************\n","steps: 193049\n","episodes: 521\n","mean 100 episode reward: -5.3\n","% time spent exploring: 0.1312795\n","********************************************************\n","episode reward: -9.089999999999849\n","********************************************************\n","steps: 194049\n","episodes: 522\n","mean 100 episode reward: -5.4\n","% time spent exploring: 0.12677949999999993\n","********************************************************\n","episode reward: -9.259999999999845\n","********************************************************\n","steps: 195049\n","episodes: 523\n","mean 100 episode reward: -5.5\n","% time spent exploring: 0.12227949999999999\n","********************************************************\n","episode reward: -9.159999999999846\n","********************************************************\n","steps: 196049\n","episodes: 524\n","mean 100 episode reward: -5.5\n","% time spent exploring: 0.11777949999999993\n","********************************************************\n","episode reward: -9.079999999999846\n","********************************************************\n","steps: 197049\n","episodes: 525\n","mean 100 episode reward: -5.6\n","% time spent exploring: 0.11327949999999998\n","********************************************************\n","episode reward: -9.199999999999848\n","********************************************************\n","steps: 198049\n","episodes: 526\n","mean 100 episode reward: -5.6\n","% time spent exploring: 0.10877949999999992\n","********************************************************\n","episode reward: -7.909999999999876\n","********************************************************\n","steps: 198899\n","episodes: 527\n","mean 100 episode reward: -5.7\n","% time spent exploring: 0.10495449999999995\n","********************************************************\n","episode reward: -8.699999999999857\n","********************************************************\n","steps: 199835\n","episodes: 528\n","mean 100 episode reward: -5.7\n","% time spent exploring: 0.10074249999999996\n","********************************************************\n","episode reward: -9.229999999999848\n","********************************************************\n","steps: 200835\n","episodes: 529\n","mean 100 episode reward: -5.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.149999999999846\n","********************************************************\n","steps: 201835\n","episodes: 530\n","mean 100 episode reward: -5.8\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.209999999999846\n","********************************************************\n","steps: 202835\n","episodes: 531\n","mean 100 episode reward: -5.8\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.359999999999845\n","********************************************************\n","steps: 203835\n","episodes: 532\n","mean 100 episode reward: -5.9\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.47999999999984\n","********************************************************\n","steps: 204835\n","episodes: 533\n","mean 100 episode reward: -5.9\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.209999999999845\n","********************************************************\n","steps: 205835\n","episodes: 534\n","mean 100 episode reward: -6.0\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.369999999999845\n","********************************************************\n","steps: 206835\n","episodes: 535\n","mean 100 episode reward: -6.0\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.449999999999841\n","********************************************************\n","steps: 207835\n","episodes: 536\n","mean 100 episode reward: -6.0\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.279999999999841\n","********************************************************\n","steps: 208835\n","episodes: 537\n","mean 100 episode reward: -6.1\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.509999999999842\n","********************************************************\n","steps: 209835\n","episodes: 538\n","mean 100 episode reward: -6.1\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.929999999999897\n","********************************************************\n","steps: 210585\n","episodes: 539\n","mean 100 episode reward: -6.1\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.079999999999844\n","********************************************************\n","steps: 211585\n","episodes: 540\n","mean 100 episode reward: -6.2\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.119999999999843\n","********************************************************\n","steps: 212585\n","episodes: 541\n","mean 100 episode reward: -6.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.279999999999845\n","********************************************************\n","steps: 213585\n","episodes: 542\n","mean 100 episode reward: -6.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.189999999999845\n","********************************************************\n","steps: 214585\n","episodes: 543\n","mean 100 episode reward: -6.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.95999999999985\n","********************************************************\n","steps: 215585\n","episodes: 544\n","mean 100 episode reward: -6.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.109999999999847\n","********************************************************\n","steps: 216585\n","episodes: 545\n","mean 100 episode reward: -6.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.089999999999844\n","********************************************************\n","steps: 217585\n","episodes: 546\n","mean 100 episode reward: -6.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.10999999999985\n","********************************************************\n","steps: 218557\n","episodes: 547\n","mean 100 episode reward: -6.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -1.7200000000000015\n","********************************************************\n","steps: 218777\n","episodes: 548\n","mean 100 episode reward: -6.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999846\n","********************************************************\n","steps: 219777\n","episodes: 549\n","mean 100 episode reward: -6.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.349999999999843\n","********************************************************\n","steps: 220777\n","episodes: 550\n","mean 100 episode reward: -6.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.329999999999844\n","********************************************************\n","steps: 221777\n","episodes: 551\n","mean 100 episode reward: -6.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.239999999999846\n","********************************************************\n","steps: 222777\n","episodes: 552\n","mean 100 episode reward: -6.8\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.349999999999842\n","********************************************************\n","steps: 223777\n","episodes: 553\n","mean 100 episode reward: -6.8\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.189999999999847\n","********************************************************\n","steps: 224777\n","episodes: 554\n","mean 100 episode reward: -6.9\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.399999999999844\n","********************************************************\n","steps: 225777\n","episodes: 555\n","mean 100 episode reward: -6.9\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.309999999999842\n","********************************************************\n","steps: 226777\n","episodes: 556\n","mean 100 episode reward: -6.9\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -1.320000000000001\n","********************************************************\n","steps: 226949\n","episodes: 557\n","mean 100 episode reward: -7.0\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.359999999999843\n","********************************************************\n","steps: 227949\n","episodes: 558\n","mean 100 episode reward: -7.0\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.13999999999985\n","********************************************************\n","steps: 228949\n","episodes: 559\n","mean 100 episode reward: -7.0\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.189999999999847\n","********************************************************\n","steps: 229949\n","episodes: 560\n","mean 100 episode reward: -7.0\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.359999999999845\n","********************************************************\n","steps: 230949\n","episodes: 561\n","mean 100 episode reward: -7.1\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.359999999999843\n","********************************************************\n","steps: 231949\n","episodes: 562\n","mean 100 episode reward: -7.1\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.129999999999871\n","********************************************************\n","steps: 232802\n","episodes: 563\n","mean 100 episode reward: -7.2\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.389999999999844\n","********************************************************\n","steps: 233802\n","episodes: 564\n","mean 100 episode reward: -7.2\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.149999999999848\n","********************************************************\n","steps: 234774\n","episodes: 565\n","mean 100 episode reward: -7.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.039999999999846\n","********************************************************\n","steps: 235774\n","episodes: 566\n","mean 100 episode reward: -7.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.219999999999848\n","********************************************************\n","steps: 236765\n","episodes: 567\n","mean 100 episode reward: -7.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.199999999999847\n","********************************************************\n","steps: 237765\n","episodes: 568\n","mean 100 episode reward: -7.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.119999999999846\n","********************************************************\n","steps: 238765\n","episodes: 569\n","mean 100 episode reward: -7.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.369999999999843\n","********************************************************\n","steps: 239765\n","episodes: 570\n","mean 100 episode reward: -7.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.369999999999843\n","********************************************************\n","steps: 240765\n","episodes: 571\n","mean 100 episode reward: -7.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.799999999999851\n","********************************************************\n","steps: 241765\n","episodes: 572\n","mean 100 episode reward: -7.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.95999999999985\n","********************************************************\n","steps: 242765\n","episodes: 573\n","mean 100 episode reward: -7.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.059999999999846\n","********************************************************\n","steps: 243765\n","episodes: 574\n","mean 100 episode reward: -7.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.769999999999877\n","********************************************************\n","steps: 244601\n","episodes: 575\n","mean 100 episode reward: -7.8\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -0.8400000000000009\n","********************************************************\n","steps: 244744\n","episodes: 576\n","mean 100 episode reward: -7.8\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.919999999999849\n","********************************************************\n","steps: 245744\n","episodes: 577\n","mean 100 episode reward: -7.8\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.279999999999864\n","********************************************************\n","steps: 246641\n","episodes: 578\n","mean 100 episode reward: -7.8\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.219999999999846\n","********************************************************\n","steps: 247641\n","episodes: 579\n","mean 100 episode reward: -7.8\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.029999999999845\n","********************************************************\n","steps: 248641\n","episodes: 580\n","mean 100 episode reward: -7.8\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -4.299999999999949\n","********************************************************\n","steps: 249151\n","episodes: 581\n","mean 100 episode reward: -7.9\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.12999999999985\n","********************************************************\n","steps: 250151\n","episodes: 582\n","mean 100 episode reward: -7.9\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.259999999999847\n","********************************************************\n","steps: 251151\n","episodes: 583\n","mean 100 episode reward: -7.9\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.519999999999841\n","********************************************************\n","steps: 252151\n","episodes: 584\n","mean 100 episode reward: -8.0\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.149999999999846\n","********************************************************\n","steps: 253151\n","episodes: 585\n","mean 100 episode reward: -8.0\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.219999999999846\n","********************************************************\n","steps: 254151\n","episodes: 586\n","mean 100 episode reward: -8.1\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.279999999999847\n","********************************************************\n","steps: 255151\n","episodes: 587\n","mean 100 episode reward: -8.1\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.409999999999844\n","********************************************************\n","steps: 256151\n","episodes: 588\n","mean 100 episode reward: -8.1\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.309999999999844\n","********************************************************\n","steps: 257151\n","episodes: 589\n","mean 100 episode reward: -8.2\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.859999999999852\n","********************************************************\n","steps: 258151\n","episodes: 590\n","mean 100 episode reward: -8.2\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.429999999999843\n","********************************************************\n","steps: 259151\n","episodes: 591\n","mean 100 episode reward: -8.2\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.209999999999843\n","********************************************************\n","steps: 260151\n","episodes: 592\n","mean 100 episode reward: -8.2\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.97999999999985\n","********************************************************\n","steps: 261151\n","episodes: 593\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.059999999999846\n","********************************************************\n","steps: 262151\n","episodes: 594\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -5.629999999999923\n","********************************************************\n","steps: 262773\n","episodes: 595\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.899999999999853\n","********************************************************\n","steps: 263713\n","episodes: 596\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.359999999999843\n","********************************************************\n","steps: 264713\n","episodes: 597\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.189999999999849\n","********************************************************\n","steps: 265713\n","episodes: 598\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999846\n","********************************************************\n","steps: 266713\n","episodes: 599\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.479999999999842\n","********************************************************\n","steps: 267713\n","episodes: 600\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.329999999999846\n","********************************************************\n","steps: 268713\n","episodes: 601\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.4699999999999065\n","********************************************************\n","steps: 269422\n","episodes: 602\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.12999999999987\n","********************************************************\n","steps: 270310\n","episodes: 603\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.369999999999845\n","********************************************************\n","steps: 271310\n","episodes: 604\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.81999999999985\n","********************************************************\n","steps: 272310\n","episodes: 605\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.319999999999846\n","********************************************************\n","steps: 273310\n","episodes: 606\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.129999999999846\n","********************************************************\n","steps: 274310\n","episodes: 607\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.509999999999842\n","********************************************************\n","steps: 275310\n","episodes: 608\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.229999999999848\n","********************************************************\n","steps: 276310\n","episodes: 609\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.119999999999846\n","********************************************************\n","steps: 277310\n","episodes: 610\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.419999999999842\n","********************************************************\n","steps: 278310\n","episodes: 611\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.139999999999848\n","********************************************************\n","steps: 279310\n","episodes: 612\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.15999999999985\n","********************************************************\n","steps: 280310\n","episodes: 613\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.269999999999845\n","********************************************************\n","steps: 281310\n","episodes: 614\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.429999999999903\n","********************************************************\n","steps: 282012\n","episodes: 615\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -4.35999999999995\n","********************************************************\n","steps: 282516\n","episodes: 616\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.349999999999842\n","********************************************************\n","steps: 283516\n","episodes: 617\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.279999999999845\n","********************************************************\n","steps: 284516\n","episodes: 618\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -4.989999999999938\n","********************************************************\n","steps: 285065\n","episodes: 619\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.389999999999844\n","********************************************************\n","steps: 286065\n","episodes: 620\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.269999999999845\n","********************************************************\n","steps: 287065\n","episodes: 621\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.099999999999843\n","********************************************************\n","steps: 288065\n","episodes: 622\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.349999999999907\n","********************************************************\n","steps: 288765\n","episodes: 623\n","mean 100 episode reward: -8.7\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.339999999999845\n","********************************************************\n","steps: 289765\n","episodes: 624\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999844\n","********************************************************\n","steps: 290765\n","episodes: 625\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.329999999999865\n","********************************************************\n","steps: 291667\n","episodes: 626\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -4.539999999999945\n","********************************************************\n","steps: 292180\n","episodes: 627\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.379999999999844\n","********************************************************\n","steps: 293180\n","episodes: 628\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.889999999999896\n","********************************************************\n","steps: 293929\n","episodes: 629\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.259999999999845\n","********************************************************\n","steps: 294929\n","episodes: 630\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -5.989999999999909\n","********************************************************\n","steps: 295618\n","episodes: 631\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -5.809999999999921\n","********************************************************\n","steps: 296268\n","episodes: 632\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -5.509999999999927\n","********************************************************\n","steps: 296859\n","episodes: 633\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.419999999999842\n","********************************************************\n","steps: 297859\n","episodes: 634\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.039999999999845\n","********************************************************\n","steps: 298859\n","episodes: 635\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.269999999999845\n","********************************************************\n","steps: 299859\n","episodes: 636\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.56999999999984\n","********************************************************\n","steps: 300859\n","episodes: 637\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.369999999999843\n","********************************************************\n","steps: 301859\n","episodes: 638\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.249999999999847\n","********************************************************\n","steps: 302859\n","episodes: 639\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.199999999999845\n","********************************************************\n","steps: 303859\n","episodes: 640\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.419999999999844\n","********************************************************\n","steps: 304859\n","episodes: 641\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.929999999999847\n","********************************************************\n","steps: 305859\n","episodes: 642\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.379999999999843\n","********************************************************\n","steps: 306859\n","episodes: 643\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.92999999999985\n","********************************************************\n","steps: 307859\n","episodes: 644\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.969999999999851\n","********************************************************\n","steps: 308859\n","episodes: 645\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -2.0899999999999994\n","********************************************************\n","steps: 309085\n","episodes: 646\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.369999999999907\n","********************************************************\n","steps: 309783\n","episodes: 647\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.459999999999862\n","********************************************************\n","steps: 310710\n","episodes: 648\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.889999999999842\n","********************************************************\n","steps: 311710\n","episodes: 649\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.019999999999845\n","********************************************************\n","steps: 312710\n","episodes: 650\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.079999999999911\n","********************************************************\n","steps: 313386\n","episodes: 651\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.379999999999843\n","********************************************************\n","steps: 314386\n","episodes: 652\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.189999999999849\n","********************************************************\n","steps: 315386\n","episodes: 653\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.309999999999846\n","********************************************************\n","steps: 316386\n","episodes: 654\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.209999999999846\n","********************************************************\n","steps: 317386\n","episodes: 655\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.339999999999845\n","********************************************************\n","steps: 318386\n","episodes: 656\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.02999999999985\n","********************************************************\n","steps: 319349\n","episodes: 657\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.219999999999848\n","********************************************************\n","steps: 320349\n","episodes: 658\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.249999999999844\n","********************************************************\n","steps: 321349\n","episodes: 659\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -3.589999999999967\n","********************************************************\n","steps: 321759\n","episodes: 660\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.419999999999844\n","********************************************************\n","steps: 322759\n","episodes: 661\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.449999999999841\n","********************************************************\n","steps: 323759\n","episodes: 662\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.719999999999873\n","********************************************************\n","steps: 324637\n","episodes: 663\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.15999999999985\n","********************************************************\n","steps: 325637\n","episodes: 664\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.359999999999845\n","********************************************************\n","steps: 326637\n","episodes: 665\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.429999999999842\n","********************************************************\n","steps: 327637\n","episodes: 666\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.569999999999881\n","********************************************************\n","steps: 328467\n","episodes: 667\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999843\n","********************************************************\n","steps: 329467\n","episodes: 668\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.329999999999846\n","********************************************************\n","steps: 330467\n","episodes: 669\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.399999999999844\n","********************************************************\n","steps: 331467\n","episodes: 670\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.13999999999985\n","********************************************************\n","steps: 332467\n","episodes: 671\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.94999999999985\n","********************************************************\n","steps: 333467\n","episodes: 672\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999844\n","********************************************************\n","steps: 334467\n","episodes: 673\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.339999999999845\n","********************************************************\n","steps: 335467\n","episodes: 674\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.419999999999842\n","********************************************************\n","steps: 336467\n","episodes: 675\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.499999999999842\n","********************************************************\n","steps: 337467\n","episodes: 676\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.349999999999842\n","********************************************************\n","steps: 338467\n","episodes: 677\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.679999999999877\n","********************************************************\n","steps: 339307\n","episodes: 678\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.609999999999896\n","********************************************************\n","steps: 340058\n","episodes: 679\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.429999999999842\n","********************************************************\n","steps: 341058\n","episodes: 680\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.329999999999844\n","********************************************************\n","steps: 342058\n","episodes: 681\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.419999999999842\n","********************************************************\n","steps: 343058\n","episodes: 682\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.159999999999846\n","********************************************************\n","steps: 344058\n","episodes: 683\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -2.949999999999981\n","********************************************************\n","steps: 344413\n","episodes: 684\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.13999999999984\n","********************************************************\n","steps: 345413\n","episodes: 685\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.119999999999868\n","********************************************************\n","steps: 346303\n","episodes: 686\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.849999999999843\n","********************************************************\n","steps: 347303\n","episodes: 687\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.459999999999841\n","********************************************************\n","steps: 348303\n","episodes: 688\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.349999999999845\n","********************************************************\n","steps: 349303\n","episodes: 689\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999846\n","********************************************************\n","steps: 350303\n","episodes: 690\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.109999999999893\n","********************************************************\n","steps: 351083\n","episodes: 691\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.46999999999984\n","********************************************************\n","steps: 352083\n","episodes: 692\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.229999999999848\n","********************************************************\n","steps: 353083\n","episodes: 693\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.329999999999846\n","********************************************************\n","steps: 354083\n","episodes: 694\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.389999999999844\n","********************************************************\n","steps: 355083\n","episodes: 695\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.85999999999985\n","********************************************************\n","steps: 356083\n","episodes: 696\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.259999999999911\n","********************************************************\n","steps: 356760\n","episodes: 697\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.989999999999868\n","********************************************************\n","steps: 357659\n","episodes: 698\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.979999999999844\n","********************************************************\n","steps: 358659\n","episodes: 699\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.6999999999999\n","********************************************************\n","steps: 359382\n","episodes: 700\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.349999999999845\n","********************************************************\n","steps: 360382\n","episodes: 701\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.229999999999846\n","********************************************************\n","steps: 361382\n","episodes: 702\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.449999999999841\n","********************************************************\n","steps: 362382\n","episodes: 703\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.369999999999845\n","********************************************************\n","steps: 363382\n","episodes: 704\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.269999999999845\n","********************************************************\n","steps: 364382\n","episodes: 705\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.8299999999998775\n","********************************************************\n","steps: 365205\n","episodes: 706\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.919999999999849\n","********************************************************\n","steps: 366205\n","episodes: 707\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -5.529999999999925\n","********************************************************\n","steps: 366823\n","episodes: 708\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.329999999999846\n","********************************************************\n","steps: 367823\n","episodes: 709\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.849999999999898\n","********************************************************\n","steps: 368559\n","episodes: 710\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -3.3899999999999717\n","********************************************************\n","steps: 368942\n","episodes: 711\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.189999999999843\n","********************************************************\n","steps: 369942\n","episodes: 712\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.359999999999843\n","********************************************************\n","steps: 370942\n","episodes: 713\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.259999999999845\n","********************************************************\n","steps: 371942\n","episodes: 714\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.079999999999847\n","********************************************************\n","steps: 372942\n","episodes: 715\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.279999999999847\n","********************************************************\n","steps: 373942\n","episodes: 716\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.419999999999844\n","********************************************************\n","steps: 374942\n","episodes: 717\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.209999999999848\n","********************************************************\n","steps: 375942\n","episodes: 718\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.46999999999984\n","********************************************************\n","steps: 376942\n","episodes: 719\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.149999999999846\n","********************************************************\n","steps: 377942\n","episodes: 720\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.369999999999843\n","********************************************************\n","steps: 378942\n","episodes: 721\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999844\n","********************************************************\n","steps: 379942\n","episodes: 722\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.0099999999999145\n","********************************************************\n","steps: 380627\n","episodes: 723\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.13999999999984\n","********************************************************\n","steps: 381627\n","episodes: 724\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999844\n","********************************************************\n","steps: 382618\n","episodes: 725\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.799999999999846\n","********************************************************\n","steps: 383618\n","episodes: 726\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.289999999999846\n","********************************************************\n","steps: 384618\n","episodes: 727\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.239999999999847\n","********************************************************\n","steps: 385618\n","episodes: 728\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.379999999999843\n","********************************************************\n","steps: 386618\n","episodes: 729\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.119999999999846\n","********************************************************\n","steps: 387618\n","episodes: 730\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.009999999999847\n","********************************************************\n","steps: 388618\n","episodes: 731\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.249999999999847\n","********************************************************\n","steps: 389618\n","episodes: 732\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999843\n","********************************************************\n","steps: 390618\n","episodes: 733\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.209999999999843\n","********************************************************\n","steps: 391618\n","episodes: 734\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.169999999999845\n","********************************************************\n","steps: 392618\n","episodes: 735\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.229999999999848\n","********************************************************\n","steps: 393618\n","episodes: 736\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.329999999999842\n","********************************************************\n","steps: 394618\n","episodes: 737\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.399999999999885\n","********************************************************\n","steps: 395414\n","episodes: 738\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.189999999999847\n","********************************************************\n","steps: 396414\n","episodes: 739\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -3.5899999999999674\n","********************************************************\n","steps: 396823\n","episodes: 740\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.289999999999845\n","********************************************************\n","steps: 397823\n","episodes: 741\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.199999999999845\n","********************************************************\n","steps: 398823\n","episodes: 742\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.129999999999846\n","********************************************************\n","steps: 399823\n","episodes: 743\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.429999999999903\n","********************************************************\n","steps: 400551\n","episodes: 744\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.249999999999845\n","********************************************************\n","steps: 401551\n","episodes: 745\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.57999999999984\n","********************************************************\n","steps: 402551\n","episodes: 746\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -5.069999999999936\n","********************************************************\n","steps: 403138\n","episodes: 747\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -4.049999999999958\n","********************************************************\n","steps: 403598\n","episodes: 748\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -2.619999999999988\n","********************************************************\n","steps: 403900\n","episodes: 749\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.289999999999845\n","********************************************************\n","steps: 404900\n","episodes: 750\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.049999999999846\n","********************************************************\n","steps: 405900\n","episodes: 751\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.399999999999842\n","********************************************************\n","steps: 406900\n","episodes: 752\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.389999999999842\n","********************************************************\n","steps: 407900\n","episodes: 753\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.409999999999844\n","********************************************************\n","steps: 408900\n","episodes: 754\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.349999999999845\n","********************************************************\n","steps: 409900\n","episodes: 755\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.249999999999847\n","********************************************************\n","steps: 410900\n","episodes: 756\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.029999999999847\n","********************************************************\n","steps: 411900\n","episodes: 757\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.179999999999843\n","********************************************************\n","steps: 412900\n","episodes: 758\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.409999999999842\n","********************************************************\n","steps: 413900\n","episodes: 759\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.389999999999844\n","********************************************************\n","steps: 414900\n","episodes: 760\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.729999999999901\n","********************************************************\n","steps: 415629\n","episodes: 761\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.39999999999984\n","********************************************************\n","steps: 416629\n","episodes: 762\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.149999999999846\n","********************************************************\n","steps: 417629\n","episodes: 763\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.329999999999846\n","********************************************************\n","steps: 418629\n","episodes: 764\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.289999999999868\n","********************************************************\n","steps: 419513\n","episodes: 765\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -1.280000000000001\n","********************************************************\n","steps: 419691\n","episodes: 766\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.389999999999844\n","********************************************************\n","steps: 420691\n","episodes: 767\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.009999999999842\n","********************************************************\n","steps: 421691\n","episodes: 768\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.179999999999843\n","********************************************************\n","steps: 422691\n","episodes: 769\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.079999999999846\n","********************************************************\n","steps: 423691\n","episodes: 770\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.869999999999877\n","********************************************************\n","steps: 424535\n","episodes: 771\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.089999999999845\n","********************************************************\n","steps: 425535\n","episodes: 772\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.419999999999844\n","********************************************************\n","steps: 426535\n","episodes: 773\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.069999999999846\n","********************************************************\n","steps: 427535\n","episodes: 774\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -4.159999999999956\n","********************************************************\n","steps: 428004\n","episodes: 775\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.359999999999843\n","********************************************************\n","steps: 429004\n","episodes: 776\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.309999999999846\n","********************************************************\n","steps: 430004\n","episodes: 777\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.269999999999841\n","********************************************************\n","steps: 431004\n","episodes: 778\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -3.609999999999967\n","********************************************************\n","steps: 431416\n","episodes: 779\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.189999999999849\n","********************************************************\n","steps: 432416\n","episodes: 780\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.329999999999846\n","********************************************************\n","steps: 433416\n","episodes: 781\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.26999999999984\n","********************************************************\n","steps: 434416\n","episodes: 782\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.259999999999847\n","********************************************************\n","steps: 435416\n","episodes: 783\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.389999999999844\n","********************************************************\n","steps: 436416\n","episodes: 784\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.929999999999852\n","********************************************************\n","steps: 437374\n","episodes: 785\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -4.87999999999994\n","********************************************************\n","steps: 437908\n","episodes: 786\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.489999999999842\n","********************************************************\n","steps: 438908\n","episodes: 787\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.439999999999841\n","********************************************************\n","steps: 439908\n","episodes: 788\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.369999999999845\n","********************************************************\n","steps: 440908\n","episodes: 789\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999843\n","********************************************************\n","steps: 441908\n","episodes: 790\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.839999999999856\n","********************************************************\n","steps: 442860\n","episodes: 791\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.449999999999843\n","********************************************************\n","steps: 443860\n","episodes: 792\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.369999999999845\n","********************************************************\n","steps: 444860\n","episodes: 793\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.409999999999842\n","********************************************************\n","steps: 445860\n","episodes: 794\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.349999999999845\n","********************************************************\n","steps: 446860\n","episodes: 795\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.159999999999847\n","********************************************************\n","steps: 447860\n","episodes: 796\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -4.299999999999953\n","********************************************************\n","steps: 448338\n","episodes: 797\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -4.709999999999944\n","********************************************************\n","steps: 448849\n","episodes: 798\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.019999999999852\n","********************************************************\n","steps: 449849\n","episodes: 799\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.379999999999843\n","********************************************************\n","steps: 450849\n","episodes: 800\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.899999999999846\n","********************************************************\n","steps: 451849\n","episodes: 801\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.339999999999844\n","********************************************************\n","steps: 452849\n","episodes: 802\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.259999999999845\n","********************************************************\n","steps: 453849\n","episodes: 803\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.13999999999985\n","********************************************************\n","steps: 454849\n","episodes: 804\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.399999999999844\n","********************************************************\n","steps: 455849\n","episodes: 805\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.559999999999905\n","********************************************************\n","steps: 456557\n","episodes: 806\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.819999999999878\n","********************************************************\n","steps: 457424\n","episodes: 807\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.539999999999903\n","********************************************************\n","steps: 458132\n","episodes: 808\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -2.999999999999978\n","********************************************************\n","steps: 458502\n","episodes: 809\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.169999999999847\n","********************************************************\n","steps: 459502\n","episodes: 810\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.789999999999848\n","********************************************************\n","steps: 460502\n","episodes: 811\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -5.969999999999917\n","********************************************************\n","steps: 461150\n","episodes: 812\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.929999999999849\n","********************************************************\n","steps: 462150\n","episodes: 813\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.209999999999846\n","********************************************************\n","steps: 463150\n","episodes: 814\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.139999999999846\n","********************************************************\n","steps: 464150\n","episodes: 815\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.419999999999842\n","********************************************************\n","steps: 465150\n","episodes: 816\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.979999999999844\n","********************************************************\n","steps: 466150\n","episodes: 817\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.419999999999844\n","********************************************************\n","steps: 467150\n","episodes: 818\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.359999999999845\n","********************************************************\n","steps: 468150\n","episodes: 819\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.049999999999846\n","********************************************************\n","steps: 469150\n","episodes: 820\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -5.059999999999936\n","********************************************************\n","steps: 469697\n","episodes: 821\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.189999999999847\n","********************************************************\n","steps: 470697\n","episodes: 822\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.319999999999846\n","********************************************************\n","steps: 471697\n","episodes: 823\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.399999999999842\n","********************************************************\n","steps: 472697\n","episodes: 824\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.139999999999844\n","********************************************************\n","steps: 473697\n","episodes: 825\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.249999999999845\n","********************************************************\n","steps: 474697\n","episodes: 826\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.399999999999842\n","********************************************************\n","steps: 475697\n","episodes: 827\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.879999999999848\n","********************************************************\n","steps: 476697\n","episodes: 828\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.46999999999984\n","********************************************************\n","steps: 477697\n","episodes: 829\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.449999999999843\n","********************************************************\n","steps: 478697\n","episodes: 830\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.53999999999984\n","********************************************************\n","steps: 479697\n","episodes: 831\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -5.879999999999919\n","********************************************************\n","steps: 480335\n","episodes: 832\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -6.829999999999899\n","********************************************************\n","steps: 481079\n","episodes: 833\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.269999999999841\n","********************************************************\n","steps: 482079\n","episodes: 834\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.119999999999841\n","********************************************************\n","steps: 483079\n","episodes: 835\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.229999999999846\n","********************************************************\n","steps: 484079\n","episodes: 836\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.349999999999845\n","********************************************************\n","steps: 485079\n","episodes: 837\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.329999999999846\n","********************************************************\n","steps: 486079\n","episodes: 838\n","mean 100 episode reward: -8.3\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.209999999999846\n","********************************************************\n","steps: 487079\n","episodes: 839\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -7.909999999999875\n","********************************************************\n","steps: 487962\n","episodes: 840\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.249999999999842\n","********************************************************\n","steps: 488962\n","episodes: 841\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.119999999999845\n","********************************************************\n","steps: 489962\n","episodes: 842\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.769999999999849\n","********************************************************\n","steps: 490962\n","episodes: 843\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.309999999999844\n","********************************************************\n","steps: 491962\n","episodes: 844\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.309999999999844\n","********************************************************\n","steps: 492962\n","episodes: 845\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -8.959999999999848\n","********************************************************\n","steps: 493962\n","episodes: 846\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.199999999999848\n","********************************************************\n","steps: 494962\n","episodes: 847\n","mean 100 episode reward: -8.4\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.199999999999847\n","********************************************************\n","steps: 495962\n","episodes: 848\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.259999999999847\n","********************************************************\n","steps: 496962\n","episodes: 849\n","mean 100 episode reward: -8.5\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.319999999999846\n","********************************************************\n","steps: 497962\n","episodes: 850\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.189999999999847\n","********************************************************\n","steps: 498962\n","episodes: 851\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n","episode reward: -9.299999999999846\n","********************************************************\n","steps: 499962\n","episodes: 852\n","mean 100 episode reward: -8.6\n","% time spent exploring: 0.09999999999999998\n","********************************************************\n"]}]},{"cell_type":"code","source":["# 1. load the scores and display the rewards over time.\n","quest_hard_scores = np.load(\"/content/gdrive/MyDrive/RL PROJECT/dqn-quest_hard_scores.npy\", allow_pickle=True)\n","plot_results(scores=quest_hard_scores)"],"metadata":{"id":"nBXTkM-OLRw_","executionInfo":{"status":"ok","timestamp":1668128440573,"user_tz":-120,"elapsed":868,"user":{"displayName":"Makoko Campbell Manape","userId":"01223048224952113583"}},"colab":{"base_uri":"https://localhost:8080/","height":404},"outputId":"f1004ce4-5930-48ea-a51d-a414e968348b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 576x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# 2. initialize the environment\n","env = gym.make(\"MiniHack-Quest-Hard-v0\", observation_keys=[\"glyphs\",\"pixel\",\"message\"],\n","               reward_win=100, reward_lose=-1, actions=NAVIGATE_ACTIONS, reward_manager=reward_manager)"],"metadata":{"id":"0XdN2erSLRjo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668128628703,"user_tz":-120,"elapsed":540,"user":{"displayName":"Makoko Campbell Manape","userId":"01223048224952113583"}},"outputId":"0078cb19-212f-4053-d1e1-28988c32167a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:32: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (21, 79)\u001b[0m\n","  \"A Box observation space has an unconventional shape (neither an image, nor a 1D vector). \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}]},{"cell_type":"code","source":["# 3. load the saved policy model to generate the video\n","model = DQN(env.action_space)\n","model.load_state_dict(torch.load(f'/content/gdrive/MyDrive/RL PROJECT/dqn-checkpoint-{seeds[0]}.pth'))\n","model.eval()"],"metadata":{"id":"BajTktQlEo9Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668128669404,"user_tz":-120,"elapsed":6,"user":{"displayName":"Makoko Campbell Manape","userId":"01223048224952113583"}},"outputId":"f92c3f82-ae29-4451-9722-44b9055d3478"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DQN(\n","  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n","  (relu1): ReLU()\n","  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n","  (relu2): ReLU()\n","  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=1600, out_features=500, bias=True)\n","  (relu3): ReLU()\n","  (fc2): Linear(in_features=500, out_features=18, bias=True)\n",")"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# 4. initialise the state and images to create a gif\n","state = env.reset()\n","images = []\n","images.append(np.uint8(state['pixel']))\n","count = 0\n","cum_reward = 0\n","\n","# continue until we terminate the game.\n","while True:\n","    # NB: No epxloration\n","    # initialize action to be random.\n","    action = env.action_space.sample()\n","\n","    # standardize the state\n","    state = format_state(state)\n","    if not torch.cuda.is_available():\n","        state = state.type(torch.FloatTensor) \n","    else:\n","        state = state.type(torch.cuda.FloatTensor)\n","    \n","    state = torch.unsqueeze(state, 0).to(device)\n","\n","    # get the best action according to the trained policy network.\n","    result = model.forward(state)\n","    action = torch.argmax(result).item()\n","    state, reward, done, _ = env.step(action)\n","    cum_reward += reward\n","    if done:\n","        break\n","    count += 1\n","    images.append(np.uint8(state['pixel']))\n","imageio.mimsave('/content/gdrive/MyDrive/RL PROJECT/dqn_agent.gif', images)\n","print('Number of Steps Taken:', count)\n","print('Total Reward:', cum_reward)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kCfrkX1K76Ch","executionInfo":{"status":"ok","timestamp":1668129020419,"user_tz":-120,"elapsed":37428,"user":{"displayName":"Makoko Campbell Manape","userId":"01223048224952113583"}},"outputId":"b86e6e55-667f-4295-c047-fc00eaa80447"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Steps Taken: 999\n","Total Reward: -9.989999999999831\n"]}]},{"cell_type":"code","source":["## 5. Display the GIF\n","Image(filename='/content/gdrive/MyDrive/RL PROJECT/dqn_agent.gif')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353,"output_embedded_package_id":"1mAE_JBKrneCZv4kMyx22Y8kTmZcDvEwI"},"id":"s5XJrNtA5hBm","executionInfo":{"status":"ok","timestamp":1668129022240,"user_tz":-120,"elapsed":1832,"user":{"displayName":"Makoko Campbell Manape","userId":"01223048224952113583"}},"outputId":"4dec3a19-e461-438d-93b9-67256c035124"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"TpU5OzEP7jgx"},"execution_count":null,"outputs":[]}]}